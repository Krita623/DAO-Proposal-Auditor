#!/usr/bin/env python3
"""
Ablation Auditor - æ¶ˆèå®éªŒå®¡è®¡å™¨

åŠŸèƒ½ï¼š
1. ç»„1ï¼šä»…ä½¿ç”¨ææ¡ˆæ–‡æœ¬è¿›è¡Œå®¡è®¡
2. ç»„2ï¼šä½¿ç”¨ææ¡ˆæ–‡æœ¬ + åŸå§‹ JSON Trace è¿›è¡Œå®¡è®¡
3. ç”Ÿæˆæ ¼å¼åŒ–çš„å®¡è®¡æŠ¥å‘Š

è¿™æ˜¯æ¶ˆèå®éªŒç‰ˆæœ¬ï¼Œç”¨äºå¯¹æ¯”å«å›¾ç»“æ„çš„å®¡è®¡æ•ˆæœã€‚
"""

import json
import re
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime

from loguru import logger
from dotenv import load_dotenv
import os

# å¯¼å…¥åŸºç¡€å®¡è®¡å™¨çš„ LLM å®¢æˆ·ç«¯
from .auditor import LLMClient, AnthropicClient, OpenAIClient

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


class AblationAuditor:
    """æ¶ˆèå®éªŒå®¡è®¡å™¨"""
    
    def __init__(self, 
                 llm_client: Optional[LLMClient] = None,
                 llm_type: str = "anthropic",
                 api_key: Optional[str] = None,
                 model: Optional[str] = None,
                 base_url: Optional[str] = None):
        """
        åˆå§‹åŒ–æ¶ˆèå®éªŒå®¡è®¡å™¨
        
        Args:
            llm_client: è‡ªå®šä¹‰ LLM å®¢æˆ·ç«¯ï¼ˆå¦‚æœæä¾›ï¼Œå°†ä½¿ç”¨æ­¤å®¢æˆ·ç«¯ï¼‰
            llm_type: LLM ç±»å‹ ("anthropic" æˆ– "openai")
            api_key: API Keyï¼ˆå¦‚æœä¸º Noneï¼Œä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
            model: æ¨¡å‹åç§°ï¼ˆå¦‚æœä¸º Noneï¼Œä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
            base_url: è‡ªå®šä¹‰ API åŸºç¡€ URLï¼ˆç”¨äºç¬¬ä¸‰æ–¹å¹³å°ï¼‰
        """
        if llm_client:
            self.llm = llm_client
        else:
            if llm_type.lower() == "anthropic":
                model = model or os.getenv("LLM_MODEL", "claude-3-5-sonnet-20241022")
                self.llm = AnthropicClient(api_key=api_key, model=model, base_url=base_url)
            elif llm_type.lower() == "openai":
                model = model or os.getenv("LLM_MODEL", "gpt-4")
                self.llm = OpenAIClient(api_key=api_key, model=model, base_url=base_url)
            else:
                raise ValueError(f"Unsupported LLM type: {llm_type}")
    
    def load_proposal(self, proposal_path: str) -> Dict[str, Any]:
        """
        åŠ è½½ææ¡ˆæ•°æ®
        
        Args:
            proposal_path: ææ¡ˆ JSON æ–‡ä»¶è·¯å¾„
            
        Returns:
            ææ¡ˆæ•°æ®å­—å…¸
        """
        proposal_file = Path(proposal_path)
        if not proposal_file.exists():
            raise FileNotFoundError(f"Proposal file not found: {proposal_path}")
        
        logger.info(f"Loading proposal from {proposal_file}")
        with open(proposal_file, 'r', encoding='utf-8') as f:
            proposal_data = json.load(f)
        
        return proposal_data
    
    def load_trace_report(self, trace_path: str) -> Dict[str, Any]:
        """
        åŠ è½½åŸå§‹ JSON Trace æ•°æ®
        
        Args:
            trace_path: trace_report.json æ–‡ä»¶è·¯å¾„
            
        Returns:
            Trace æ•°æ®å­—å…¸
        """
        trace_file = Path(trace_path)
        if not trace_file.exists():
            raise FileNotFoundError(f"Trace report not found: {trace_path}")
        
        logger.info(f"Loading trace report from {trace_file}")
        with open(trace_file, 'r', encoding='utf-8') as f:
            trace_data = json.load(f)
        
        return trace_data
    
    def format_trace_summary(self, trace_data: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ– Trace æ‘˜è¦ä¸ºå¯è¯»æ–‡æœ¬ï¼ˆä½¿ç”¨ trace_summaryï¼‰
        
        æ³¨æ„ï¼šæ­¤æ–¹æ³•ç”¨äºæ ¼å¼åŒ–å¤„ç†åçš„ trace_summary æ•°æ®ã€‚
        ç»„1ä¸ä½¿ç”¨ä»»ä½• trace æ•°æ®ï¼Œæ­¤æ–¹æ³•ä»…åœ¨ format_full_trace() çš„å›é€€é€»è¾‘ä¸­ä½¿ç”¨ã€‚
        
        Args:
            trace_data: Trace æ•°æ®å­—å…¸
            
        Returns:
            æ ¼å¼åŒ–çš„ Trace æ‘˜è¦æ–‡æœ¬
        """
        trace_summary = trace_data.get("trace_summary", {})
        calls = trace_summary.get("calls", [])
        total_calls = trace_summary.get("total_calls", len(calls))
        max_depth = trace_summary.get("max_depth", 0)
        
        formatted = f"""## æ‰§è¡Œè½¨è¿¹æ‘˜è¦

- **æ€»è°ƒç”¨æ•°**: {total_calls}
- **æœ€å¤§æ·±åº¦**: {max_depth}

### è°ƒç”¨åˆ—è¡¨

"""
        
        # é™åˆ¶æ˜¾ç¤ºçš„è°ƒç”¨æ•°é‡ï¼ˆé¿å… prompt è¿‡é•¿ï¼‰
        max_display_calls = 50
        display_calls = calls[:max_display_calls]
        
        for i, call in enumerate(display_calls, 1):
            call_type = call.get("type", "UNKNOWN")
            from_addr = call.get("from", "N/A")
            to_addr = call.get("to", "N/A")
            value = call.get("value", 0)
            depth = call.get("depth", 0)
            function = call.get("function_signature", call.get("function_selector", "unknown"))
            
            formatted += f"{i}. **{call_type}** (æ·±åº¦: {depth})\n"
            formatted += f"   - From: `{from_addr}`\n"
            formatted += f"   - To: `{to_addr}`\n"
            formatted += f"   - Value: {value} wei\n"
            formatted += f"   - Function: `{function}`\n\n"
        
        if len(calls) > max_display_calls:
            formatted += f"\n*ï¼ˆä»…æ˜¾ç¤ºå‰ {max_display_calls} ä¸ªè°ƒç”¨ï¼Œå…± {total_calls} ä¸ªè°ƒç”¨ï¼‰*\n"
        
        return formatted
    
    def format_full_trace(self, trace_data: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–å®Œæ•´ Trace æ•°æ®ä¸ºå¯è¯»æ–‡æœ¬ï¼ˆç”¨äºç»„2ï¼Œä½¿ç”¨å®Œæ•´çš„ trace_callsï¼‰
        
        Args:
            trace_data: Trace æ•°æ®å­—å…¸
            
        Returns:
            æ ¼å¼åŒ–çš„å®Œæ•´ Trace æ–‡æœ¬
        """
        # è·å–å®Œæ•´çš„ trace_callsï¼ˆåŸå§‹ trace æ•°æ®ï¼‰
        trace_calls = trace_data.get("trace_calls", [])
        
        if not trace_calls:
            # å¦‚æœæ²¡æœ‰ trace_callsï¼Œå›é€€åˆ° trace_summary
            logger.warning("trace_calls not found, falling back to trace_summary")
            return self.format_trace_summary(trace_data)
        
        # è·å–äº¤æ˜“ä¿¡æ¯
        original_tx = trace_data.get("original_transaction", {})
        replay_tx = trace_data.get("replay_transaction", {})
        fork_config = trace_data.get("fork_config", {})
        
        formatted = f"""## å®Œæ•´æ‰§è¡Œè½¨è¿¹ï¼ˆåŸå§‹ Trace æ•°æ®ï¼‰

### äº¤æ˜“ä¿¡æ¯
- **åŸå§‹äº¤æ˜“å“ˆå¸Œ**: {original_tx.get('hash', 'N/A')}
- **é‡æ”¾äº¤æ˜“å“ˆå¸Œ**: {replay_tx.get('hash', 'N/A')}
- **Fork åŒºå—å·**: {fork_config.get('fork_block_number', 'N/A')}
- **åŸå§‹åŒºå—å·**: {fork_config.get('original_block_number', 'N/A')}

### Trace è°ƒç”¨åˆ—è¡¨ï¼ˆå…± {len(trace_calls)} ä¸ªè°ƒç”¨ï¼‰

"""
        
        # æ ¼å¼åŒ–æ¯ä¸ª trace call
        for i, call in enumerate(trace_calls, 1):
            call_type = call.get("type", "UNKNOWN")
            from_addr = call.get("from", "N/A")
            to_addr = call.get("to", "N/A")
            value = call.get("value", "0")
            gas = call.get("gas", "N/A")
            gas_used = call.get("gasUsed", "N/A")
            input_data = call.get("input", "")
            output_data = call.get("output", "")
            
            # å°è¯•æå–å‡½æ•°ç­¾åï¼ˆå¦‚æœæœ‰ï¼‰
            function_info = ""
            if input_data and len(input_data) >= 10:
                function_selector = input_data[:10]
                # å°è¯•ä» trace_summary ä¸­åŒ¹é…å‡½æ•°ç­¾å
                trace_summary = trace_data.get("trace_summary", {})
                summary_calls = trace_summary.get("calls", [])
                for summary_call in summary_calls:
                    if summary_call.get("to", "").lower() == to_addr.lower():
                        func_sig = summary_call.get("function_signature", summary_call.get("function_selector", ""))
                        if func_sig and func_sig != "unknown":
                            function_info = f" ({func_sig})"
                            break
                if not function_info:
                    function_info = f" (selector: {function_selector})"
            
            formatted += f"{i}. **{call_type}**\n"
            formatted += f"   - From: `{from_addr}`\n"
            formatted += f"   - To: `{to_addr}`\n"
            formatted += f"   - Value: {value} wei\n"
            if gas != "N/A":
                formatted += f"   - Gas: {gas}\n"
            if gas_used != "N/A":
                formatted += f"   - Gas Used: {gas_used}\n"
            if function_info:
                formatted += f"   - Function: `{function_info.strip(' ()')}`\n"
            if input_data and len(input_data) > 10:
                # åªæ˜¾ç¤º input çš„å‰100ä¸ªå­—ç¬¦
                input_preview = input_data[:100] + "..." if len(input_data) > 100 else input_data
                formatted += f"   - Input: `{input_preview}`\n"
            if output_data:
                # åªæ˜¾ç¤º output çš„å‰100ä¸ªå­—ç¬¦
                output_preview = output_data[:100] + "..." if len(output_data) > 100 else output_data
                formatted += f"   - Output: `{output_preview}`\n"
            
            # å¦‚æœæœ‰å­è°ƒç”¨ï¼ˆcalls å­—æ®µï¼‰
            if "calls" in call and call["calls"]:
                formatted += f"   - å­è°ƒç”¨æ•°: {len(call['calls'])}\n"
            
            formatted += "\n"
        
        return formatted
    
    def build_audit_prompt_group1(self, proposal_description: str, proposal_data: Dict[str, Any]) -> str:
        """
        æ„å»ºç»„1çš„å®¡è®¡ Promptï¼ˆä»…ææ¡ˆæ–‡æœ¬ï¼‰
        
        Args:
            proposal_description: ææ¡ˆæ–‡æœ¬æè¿°
            proposal_data: ææ¡ˆæ•°æ®
            
        Returns:
            å®Œæ•´çš„å®¡è®¡ Prompt
        """
        # æå–ææ¡ˆçš„æŠ€æœ¯ç»†èŠ‚
        targets = proposal_data.get("targets", [])
        values = proposal_data.get("values", [])
        calldatas = proposal_data.get("calldatas", [])
        
        technical_details = f"""
### ææ¡ˆæŠ€æœ¯å‚æ•°ï¼š
- **ç›®æ ‡åˆçº¦åœ°å€ (targets)**: {', '.join(targets) if targets else 'æ— '}
- **ETH è½¬è´¦é‡‘é¢ (values)**: {values}
- **å‡½æ•°è°ƒç”¨æ•°æ® (calldatas)**: {len(calldatas)} ä¸ªè°ƒç”¨
"""
        
        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ™ºèƒ½åˆçº¦å®‰å…¨å®¡è®¡ä¸“å®¶ã€‚è¯·å¯¹ä»¥ä¸‹ DAO ææ¡ˆè¿›è¡Œæ·±åº¦å®¡è®¡åˆ†æã€‚

## å®éªŒè¯´æ˜

**è¿™æ˜¯æ¶ˆèå®éªŒç»„1**ï¼šæœ¬æ¬¡å®¡è®¡**ä»…ä½¿ç”¨ææ¡ˆæ–‡æœ¬å’ŒæŠ€æœ¯å‚æ•°**ï¼Œä¸åŒ…å«æ‰§è¡Œè½¨è¿¹ä¿¡æ¯ã€‚

## ä»»åŠ¡è¯´æ˜

ä½ éœ€è¦æ‰§è¡Œä»¥ä¸‹æ ¸å¿ƒå®¡è®¡ä»»åŠ¡ï¼š

### 1. [Text Analysis] æ–‡æœ¬ä¸€è‡´æ€§åˆ†æ
åˆ†æææ¡ˆæ–‡æœ¬æè¿°æ˜¯å¦æ¸…æ™°ã€å®Œæ•´ï¼Œæ˜¯å¦å­˜åœ¨æ¨¡ç³Šæˆ–å¯èƒ½è¯¯å¯¼çš„è¡¨è¿°ã€‚

### 2. [Technical Parameter Review] æŠ€æœ¯å‚æ•°å®¡æŸ¥
å®¡æŸ¥ææ¡ˆä¸­çš„æŠ€æœ¯å‚æ•°ï¼ˆtargets, values, calldatasï¼‰æ˜¯å¦ä¸æ–‡æœ¬æè¿°ä¸€è‡´ï¼š
- æ£€æŸ¥ç›®æ ‡åˆçº¦åœ°å€æ˜¯å¦åœ¨æ–‡æœ¬ä¸­æ˜ç¡®æåˆ°
- æ£€æŸ¥ ETH è½¬è´¦é‡‘é¢æ˜¯å¦ä¸æ–‡æœ¬æè¿°ä¸€è‡´
- æ£€æŸ¥æ˜¯å¦å­˜åœ¨æœªåœ¨æ–‡æœ¬ä¸­è¯´æ˜çš„åˆçº¦è°ƒç”¨

### 3. [Risk Assessment] é£é™©è¯„ä¼°
åŸºäºææ¡ˆæ–‡æœ¬å’ŒæŠ€æœ¯å‚æ•°ï¼Œè¯†åˆ«æ½œåœ¨çš„å®‰å…¨é£é™©ï¼š
- æœªæ˜ç¡®è¯´æ˜çš„åˆçº¦è°ƒç”¨
- å¯èƒ½å­˜åœ¨çš„æƒé™æå‡é£é™©
- èµ„é‡‘è½¬ç§»é£é™©
- ç³»ç»Ÿå‡çº§é£é™©

### 4. [Completeness Check] å®Œæ•´æ€§æ£€æŸ¥
è¯„ä¼°ææ¡ˆæ–‡æœ¬æ˜¯å¦æä¾›äº†è¶³å¤Ÿçš„ä¿¡æ¯ä¾›ç¤¾åŒºåšå‡ºæ˜æ™ºå†³ç­–ã€‚

## è¾“å…¥æ•°æ®

### ææ¡ˆæ–‡æœ¬æè¿°ï¼š
```
{proposal_description}
```

{technical_details}

## è¾“å‡ºè¦æ±‚

è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºå®¡è®¡ç»“æœï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

```json
{{
  "consistency_score": <1-10 çš„æ•´æ•°ï¼Œ10 è¡¨ç¤ºå®Œå…¨ä¸€è‡´ï¼Œ1 è¡¨ç¤ºä¸¥é‡ä¸ä¸€è‡´>,
  "text_analysis": {{
    "clarity_score": <1-10 çš„æ•´æ•°ï¼Œæ–‡æœ¬æ¸…æ™°åº¦è¯„åˆ†>,
    "completeness_score": <1-10 çš„æ•´æ•°ï¼Œæ–‡æœ¬å®Œæ•´æ€§è¯„åˆ†>,
    "issues": [
      {{
        "type": "<é—®é¢˜ç±»å‹>",
        "severity": "<low|medium|high>",
        "description": "<é—®é¢˜æè¿°>"
      }}
    ]
  }},
  "technical_parameter_review": {{
    "mentioned_contracts": [
      "<åœ¨æ–‡æœ¬ä¸­æ˜ç¡®æåˆ°çš„åˆçº¦åœ°å€åˆ—è¡¨>"
    ],
    "unmentioned_contracts": [
      {{
        "address": "<æœªåœ¨æ–‡æœ¬ä¸­æåˆ°çš„åˆçº¦åœ°å€>",
        "risk_level": "<low|medium|high>",
        "description": "<é£é™©è¯„ä¼°>"
      }}
    ],
    "value_consistency": {{
      "is_consistent": <true|false>,
      "description": "<ETH è½¬è´¦é‡‘é¢ä¸æ–‡æœ¬æè¿°çš„ä¸€è‡´æ€§åˆ†æ>"
    }}
  }},
  "risk_assessment": {{
    "identified_risks": [
      {{
        "type": "<é£é™©ç±»å‹>",
        "severity": "<low|medium|high|critical>",
        "description": "<è¯¦ç»†çš„é£é™©æè¿°>",
        "recommendation": "<å»ºè®®çš„åº”å¯¹æªæ–½>"
      }}
    ],
    "overall_risk_level": "<low|medium|high|critical>"
  }},
  "completeness_check": {{
    "missing_information": [
      {{
        "type": "<ç¼ºå¤±ä¿¡æ¯ç±»å‹>",
        "importance": "<low|medium|high>",
        "description": "<ç¼ºå¤±ä¿¡æ¯çš„æè¿°>"
      }}
    ],
    "sufficient_for_decision": <true|false>,
    "recommendation": "<æ˜¯å¦å»ºè®®é€šè¿‡æ­¤ææ¡ˆ>"
  }},
  "security_conclusion": "<æ€»ä½“å®‰å…¨ç»“è®ºï¼ŒåŒ…æ‹¬æ˜¯å¦å»ºè®®é€šè¿‡æ­¤ææ¡ˆ>",
  "summary": "<ç®€è¦æ€»ç»“ï¼Œ2-3 å¥è¯>",
  "limitations": "<ç”±äºæœªä½¿ç”¨æ‰§è¡Œè½¨è¿¹åˆ†æï¼Œæœ¬æ¬¡å®¡è®¡çš„å±€é™æ€§è¯´æ˜>"
}}
```

è¯·ä»”ç»†åˆ†æï¼Œç¡®ä¿è¾“å‡ºæœ‰æ•ˆçš„ JSON æ ¼å¼ã€‚"""
        
        return prompt
    
    def build_audit_prompt_group2(self, proposal_description: str, proposal_data: Dict[str, Any], 
                                 trace_data: Dict[str, Any]) -> str:
        """
        æ„å»ºç»„2çš„å®¡è®¡ Promptï¼ˆææ¡ˆæ–‡æœ¬ + åŸå§‹ JSON Traceï¼‰
        
        Args:
            proposal_description: ææ¡ˆæ–‡æœ¬æè¿°
            proposal_data: ææ¡ˆæ•°æ®
            trace_data: Trace æ•°æ®
            
        Returns:
            å®Œæ•´çš„å®¡è®¡ Prompt
        """
        # æå–ææ¡ˆçš„æŠ€æœ¯ç»†èŠ‚
        targets = proposal_data.get("targets", [])
        values = proposal_data.get("values", [])
        calldatas = proposal_data.get("calldatas", [])
        
        technical_details = f"""
### ææ¡ˆæŠ€æœ¯å‚æ•°ï¼š
- **ç›®æ ‡åˆçº¦åœ°å€ (targets)**: {', '.join(targets) if targets else 'æ— '}
- **ETH è½¬è´¦é‡‘é¢ (values)**: {values}
- **å‡½æ•°è°ƒç”¨æ•°æ® (calldatas)**: {len(calldatas)} ä¸ªè°ƒç”¨
"""
        
        # æ ¼å¼åŒ–å®Œæ•´ Trace æ•°æ®ï¼ˆä½¿ç”¨ trace_callsï¼‰
        trace_summary_text = self.format_full_trace(trace_data)
        
        # æå–å®Œæ•´çš„ Trace JSONï¼ˆä½¿ç”¨å®Œæ•´çš„ trace_callsï¼‰
        trace_calls = trace_data.get("trace_calls", [])
        if trace_calls:
            # ä½¿ç”¨å®Œæ•´çš„ trace_calls
            trace_json = json.dumps({
                "trace_calls": trace_calls,
                "original_transaction": trace_data.get("original_transaction", {}),
                "replay_transaction": trace_data.get("replay_transaction", {}),
                "fork_config": trace_data.get("fork_config", {})
            }, indent=2, ensure_ascii=False)
        else:
            # å›é€€åˆ° trace_summary
            logger.warning("trace_calls not found, using trace_summary instead")
            trace_summary = trace_data.get("trace_summary", {})
            trace_json = json.dumps(trace_summary, indent=2, ensure_ascii=False)
        
        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ™ºèƒ½åˆçº¦å®‰å…¨å®¡è®¡ä¸“å®¶ã€‚è¯·å¯¹ä»¥ä¸‹ DAO ææ¡ˆè¿›è¡Œæ·±åº¦å®¡è®¡åˆ†æã€‚

## å®éªŒè¯´æ˜

**è¿™æ˜¯æ¶ˆèå®éªŒç»„2**ï¼šæœ¬æ¬¡å®¡è®¡ä½¿ç”¨**ææ¡ˆæ–‡æœ¬ + å®Œæ•´åŸå§‹ JSON Trace æ•°æ®ï¼ˆtrace_callsï¼‰**ï¼Œä½†ä¸ä½¿ç”¨å›¾ç»“æ„åˆ†æã€‚

**é‡è¦**ï¼šæœ¬ç»„ä½¿ç”¨å®Œæ•´çš„åŸå§‹ Trace æ•°æ®ï¼ˆtrace_callsï¼‰ï¼ŒåŒ…å«æ‰€æœ‰è°ƒç”¨çš„è¯¦ç»†ä¿¡æ¯ï¼ˆinputã€outputã€gas ç­‰ï¼‰ï¼Œè€Œä¸æ˜¯å¤„ç†åçš„ trace_summaryã€‚

## ä»»åŠ¡è¯´æ˜

ä½ éœ€è¦æ‰§è¡Œä»¥ä¸‹æ ¸å¿ƒå®¡è®¡ä»»åŠ¡ï¼š

### 1. [Conflict Detection] å†²çªæ£€æµ‹
å¯¹æ¯”ææ¡ˆæ–‡æœ¬æè¿°ä¸å®é™…æ‰§è¡Œè½¨è¿¹ï¼ˆTraceï¼‰ï¼Œæ£€æŸ¥ï¼š
- å®é™…æ‰§è¡Œçš„åˆçº¦åœ°å€æ˜¯å¦åœ¨ææ¡ˆæ–‡æœ¬ä¸­æ˜ç¡®æåˆ°
- æ˜¯å¦å­˜åœ¨æœªåœ¨æ–‡æœ¬ä¸­è¯´æ˜çš„åˆçº¦è°ƒç”¨
- è°ƒç”¨æ·±åº¦å’Œå¤æ‚åº¦æ˜¯å¦ä¸æ–‡æœ¬æè¿°ä¸€è‡´

**é‡è¦ï¼šå¸¸è¯†æ£€æŸ¥è§„åˆ™**
- å¦‚æœ Trace ä¸­å‡ºç°çš„åœ°å€å±äºä»¥ä¸‹ç±»å‹ï¼Œ**ä¸åº”è§†ä¸ºæœªæŠ«éœ²é£é™©**ï¼š
  1. **ä»¥å¤ªåŠé¢„ç¼–è¯‘åˆçº¦**ï¼šåœ°å€èŒƒå›´ 0x1-0x9
  2. **L2 ç³»ç»Ÿåˆçº¦**ï¼šå¦‚ Arbitrum çš„ 0x64ï¼ˆL1 ArbSysï¼‰ã€0x65ï¼ˆL2 ArbSysï¼‰ç­‰
  3. **æ ‡å‡†ä»£ç†è½¬å‘é€»è¾‘**ï¼šé€šè¿‡ DELEGATECALL å®ç°çš„ä»£ç†æ¨¡å¼

### 2. [Depth Analysis] æ·±åº¦åˆ†æ
åˆ†æ Trace ä¸­çš„è°ƒç”¨æ·±åº¦ï¼š
- å¦‚æœææ¡ˆæ–‡æœ¬å£°ç§°æ˜¯"ç®€å•æ›´æ–°"æˆ–"è½»å¾®ä¿®æ”¹"ï¼Œä½† Trace æ˜¾ç¤ºæ·±åº¦è¾¾åˆ° 4 æˆ–æ›´é«˜ï¼Œè¯·åˆ†ææ˜¯å¦å­˜åœ¨"æ¶æ„éšè—æ·±åº¦"çš„é£é™©
- è¯„ä¼°å®é™…æ‰§è¡Œå¤æ‚åº¦æ˜¯å¦ä¸æ–‡æœ¬æè¿°ä¸€è‡´

### 3. [Function Semantic Match] å‡½æ•°è¯­ä¹‰åŒ¹é…
æ£€æŸ¥ Trace ä¸­æ‰§è¡Œçš„å‡½æ•°åæ˜¯å¦ä¸ææ¡ˆæ–‡æœ¬æ‰€è¿°çš„æ„å›¾å»åˆï¼š
- è¯†åˆ«ä»»ä½•è¯­ä¹‰ä¸ä¸€è‡´æˆ–æœªå…¬å¼€çš„å‡½æ•°è°ƒç”¨
- æ£€æŸ¥å‡½æ•°è°ƒç”¨çš„å‚æ•°å’Œè¿”å›å€¼æ˜¯å¦ç¬¦åˆé¢„æœŸ

### 4. [Risk Assessment] é£é™©è¯„ä¼°
åŸºäºææ¡ˆæ–‡æœ¬å’Œ Trace æ•°æ®ï¼Œè¯†åˆ«æ½œåœ¨çš„å®‰å…¨é£é™©ã€‚

## è¾“å…¥æ•°æ®

### ææ¡ˆæ–‡æœ¬æè¿°ï¼š
```
{proposal_description}
```

{technical_details}

{trace_summary_text}

### å®Œæ•´åŸå§‹ Trace JSON æ•°æ®ï¼ˆtrace_callsï¼‰ï¼š
```json
{trace_json}
```

**æ³¨æ„**ï¼šè¿™æ˜¯å®Œæ•´çš„åŸå§‹ Trace æ•°æ®ï¼ˆtrace_callsï¼‰ï¼ŒåŒ…å«æ‰€æœ‰è°ƒç”¨çš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬ inputã€outputã€gas ä½¿ç”¨ç­‰ã€‚è¯·ä»”ç»†åˆ†ææ¯ä¸ªè°ƒç”¨çš„å®Œæ•´ä¸Šä¸‹æ–‡ã€‚

## è¾“å‡ºè¦æ±‚

è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºå®¡è®¡ç»“æœï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

```json
{{
  "consistency_score": <1-10 çš„æ•´æ•°ï¼Œ10 è¡¨ç¤ºå®Œå…¨ä¸€è‡´ï¼Œ1 è¡¨ç¤ºä¸¥é‡ä¸ä¸€è‡´>,
  "conflict_detection": {{
    "unaccounted_contracts": [
      {{
        "address": "<åˆçº¦åœ°å€>",
        "risk_level": "<low|medium|high>",
        "description": "<ä¸ºä»€ä¹ˆè¿™ä¸ªåœ°å€æœªåœ¨æ–‡æœ¬ä¸­æåˆ°ï¼Œå¯èƒ½çš„é£é™©>",
        "is_system_contract": <true|false>,
        "contract_type": "<SYSTEM_LEVEL_CALL|UNACCOUNTED_CONTRACT>"
      }}
    ],
    "system_level_calls": [
      {{
        "address": "<ç³»ç»Ÿåˆçº¦åœ°å€>",
        "type": "<é¢„ç¼–è¯‘åˆçº¦|L2ç³»ç»Ÿåˆçº¦|ä»£ç†è½¬å‘>",
        "description": "<ç³»ç»Ÿåˆçº¦çš„ç”¨é€”è¯´æ˜>"
      }}
    ],
    "mentioned_contracts": [
      "<åœ¨æ–‡æœ¬ä¸­æ˜ç¡®æåˆ°çš„åˆçº¦åœ°å€åˆ—è¡¨>"
    ]
  }},
  "depth_analysis": {{
    "claimed_complexity": "<æ–‡æœ¬ä¸­å£°ç§°çš„å¤æ‚åº¦æè¿°>",
    "actual_depth": <å®é™… Trace æ·±åº¦>,
    "depth_mismatch": <true|false>,
    "risk_assessment": "<å¦‚æœå­˜åœ¨æ·±åº¦ä¸åŒ¹é…ï¼Œè¯„ä¼°é£é™©ç­‰çº§å’ŒåŸå› >"
  }},
  "function_semantic_match": {{
    "matched_functions": [
      {{
        "function": "<å‡½æ•°å>",
        "description": "<ä¸æ–‡æœ¬æè¿°çš„åŒ¹é…æƒ…å†µ>"
      }}
    ],
    "unmatched_functions": [
      {{
        "function": "<å‡½æ•°å>",
        "description": "<ä¸ºä»€ä¹ˆè¿™ä¸ªå‡½æ•°è°ƒç”¨ä¸æ–‡æœ¬æè¿°ä¸åŒ¹é…>",
        "risk_level": "<low|medium|high>"
      }}
    ]
  }},
  "potential_risks": [
    {{
      "type": "<é£é™©ç±»å‹ï¼Œå¦‚ UNACCOUNTED_CONTRACT, DEPTH_MISMATCH, FUNCTION_MISMATCH ç­‰>",
      "severity": "<low|medium|high|critical>",
      "description": "<è¯¦ç»†çš„é£é™©æè¿°>",
      "recommendation": "<å»ºè®®çš„åº”å¯¹æªæ–½>"
    }}
  ],
  "security_conclusion": "<æ€»ä½“å®‰å…¨ç»“è®ºï¼ŒåŒ…æ‹¬æ˜¯å¦å»ºè®®é€šè¿‡æ­¤ææ¡ˆ>",
  "summary": "<ç®€è¦æ€»ç»“ï¼Œ2-3 å¥è¯>",
  "limitations": "<ç”±äºæœªä½¿ç”¨å›¾ç»“æ„åˆ†æï¼Œæœ¬æ¬¡å®¡è®¡çš„å±€é™æ€§è¯´æ˜>"
}}
```

è¯·ä»”ç»†åˆ†æï¼Œç¡®ä¿è¾“å‡ºæœ‰æ•ˆçš„ JSON æ ¼å¼ã€‚"""
        
        return prompt
    
    def parse_llm_response(self, response_text: str) -> Dict[str, Any]:
        """
        è§£æ LLM å“åº”ï¼Œæå– JSON
        
        Args:
            response_text: LLM å“åº”æ–‡æœ¬
            
        Returns:
            è§£æåçš„ JSON å­—å…¸
        """
        # å°è¯•æå– JSONï¼ˆå¯èƒ½è¢« ```json ... ``` åŒ…è£¹ï¼‰
        json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            # å°è¯•æå– {...} æ ¼å¼çš„ JSON
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
            else:
                json_str = response_text
        
        try:
            result = json.loads(json_str)
            return result
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse LLM response as JSON: {e}")
            logger.debug(f"Response text: {response_text[:500]}")
            # è¿”å›ä¸€ä¸ªé»˜è®¤ç»“æ„
            return {
                "consistency_score": 5,
                "error": "Failed to parse LLM response",
                "raw_response": response_text[:1000]
            }
    
    def generate_markdown_report(self, audit_result: Dict[str, Any], 
                                 proposal_id: Optional[str] = None,
                                 group: int = 1) -> str:
        """
        ç”Ÿæˆ Markdown æ ¼å¼çš„å®¡è®¡æŠ¥å‘Š
        
        Args:
            audit_result: å®¡è®¡ç»“æœå­—å…¸
            proposal_id: ææ¡ˆ IDï¼ˆå¯é€‰ï¼‰
            group: å®éªŒç»„ç¼–å·ï¼ˆ1 æˆ– 2ï¼‰
            
        Returns:
            Markdown æ ¼å¼çš„æŠ¥å‘Šæ–‡æœ¬
        """
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        group_name = "ç»„1ï¼šä»…ææ¡ˆæ–‡æœ¬" if group == 1 else "ç»„2ï¼šææ¡ˆæ–‡æœ¬ + åŸå§‹ JSON Trace"
        
        report = f"""# DAO ææ¡ˆå®¡è®¡æŠ¥å‘Šï¼ˆæ¶ˆèå®éªŒ {group_name}ï¼‰

**ç”Ÿæˆæ—¶é—´**: {timestamp}  
**ææ¡ˆ ID**: {proposal_id or "N/A"}  
**å®éªŒç±»å‹**: æ¶ˆèå®éªŒ {group_name}

---

## âš ï¸ å®éªŒè¯´æ˜

æœ¬æŠ¥å‘Šæ˜¯åŸºäº**æ¶ˆèå®éªŒç»„{group}**ç”Ÿæˆçš„å®¡è®¡æŠ¥å‘Šã€‚ä¸æ ‡å‡†å®¡è®¡æµç¨‹ï¼ˆå«å›¾ç»“æ„ï¼‰ä¸åŒï¼Œæœ¬æ¬¡å®¡è®¡ï¼š
"""
        
        if group == 1:
            report += """- âŒ **æœªä½¿ç”¨**æ‰§è¡Œè½¨è¿¹ä¿¡æ¯
- âŒ **æœªä½¿ç”¨**å›¾ç»“æ„åˆ†æ
- âœ… **ä»…åŸºäº**ææ¡ˆæ–‡æœ¬å’ŒæŠ€æœ¯å‚æ•°è¿›è¡Œåˆ†æ

**å±€é™æ€§**: ç”±äºæœªåˆ†æå®é™…æ‰§è¡Œè½¨è¿¹ï¼Œæ— æ³•æ£€æµ‹ï¼š
- éšè—çš„æ·±åº¦è°ƒç”¨é“¾
- æœªå…¬å¼€çš„å‡½æ•°è°ƒç”¨
- ä»£ç†åˆçº¦è½¬å‘é€»è¾‘
- å®é™…æ‰§è¡Œå¤æ‚åº¦
"""
        else:
            report += """- âœ… **ä½¿ç”¨**å®Œæ•´åŸå§‹ JSON Trace æ•°æ®ï¼ˆtrace_callsï¼‰
- âŒ **æœªä½¿ç”¨**å›¾ç»“æ„åˆ†æ
- âœ… **åŸºäº**ææ¡ˆæ–‡æœ¬å’Œå®Œæ•´ Trace æ•°æ®è¿›è¡Œåˆ†æ

**æ•°æ®è¯´æ˜**: æœ¬ç»„ä½¿ç”¨å®Œæ•´çš„åŸå§‹ Trace æ•°æ®ï¼ˆtrace_callsï¼‰ï¼ŒåŒ…å«æ‰€æœ‰è°ƒç”¨çš„è¯¦ç»†ä¿¡æ¯ï¼ˆinputã€outputã€gas ç­‰ï¼‰ï¼Œè€Œä¸æ˜¯å¤„ç†åçš„ trace_summaryã€‚

**å±€é™æ€§**: ç”±äºæœªä½¿ç”¨å›¾ç»“æ„åˆ†æï¼Œå¯èƒ½æ— æ³•ï¼š
- ç›´è§‚åœ°è¯†åˆ«è°ƒç”¨é“¾çš„æ‹“æ‰‘ç»“æ„
- å¿«é€Ÿè¯†åˆ«ä¸­å¿ƒèŠ‚ç‚¹å’Œå…³é”®è·¯å¾„
- åˆ©ç”¨å›¾ç®—æ³•è¿›è¡Œæ·±åº¦åˆ†æ
"""
        
        report += "\n---\n\n## ğŸ“Š ä¸€è‡´æ€§è¯„åˆ†\n\n"
        report += f"**è¯„åˆ†**: **{audit_result.get('consistency_score', 'N/A')}/10**\n\n"
        report += f"{self._get_score_description(audit_result.get('consistency_score', 5))}\n\n"
        
        # æ ¹æ®ç»„åˆ«ç”Ÿæˆä¸åŒçš„æŠ¥å‘Šå†…å®¹
        if group == 1:
            # ç»„1çš„æŠ¥å‘Šæ ¼å¼
            report += self._generate_group1_report_content(audit_result)
        else:
            # ç»„2çš„æŠ¥å‘Šæ ¼å¼ï¼ˆç±»ä¼¼æ ‡å‡†å®¡è®¡ï¼Œä½†ä¸ä½¿ç”¨å›¾ç»“æ„ï¼‰
            report += self._generate_group2_report_content(audit_result)
        
        limitations = audit_result.get("limitations", "")
        if limitations:
            report += "\n---\n\n## âš ï¸ å®¡è®¡å±€é™æ€§\n\n"
            report += f"{limitations}\n\n"
        
        report += "\n---\n\n"
        report += f"*æœ¬æŠ¥å‘Šç”± AI è‡ªåŠ¨ç”Ÿæˆï¼ˆæ¶ˆèå®éªŒç»„{group}ï¼‰ï¼Œä»…ä¾›å‚è€ƒã€‚å»ºè®®ç»“åˆæ ‡å‡†å®¡è®¡æµç¨‹ï¼ˆå«å›¾ç»“æ„ï¼‰è¿›è¡Œæœ€ç»ˆå†³ç­–ã€‚*\n"
        
        return report
    
    def _generate_group1_report_content(self, audit_result: Dict[str, Any]) -> str:
        """ç”Ÿæˆç»„1çš„æŠ¥å‘Šå†…å®¹"""
        content = "## ğŸ“ æ–‡æœ¬åˆ†æ (Text Analysis)\n\n"
        
        text_analysis = audit_result.get("text_analysis", {})
        clarity_score = text_analysis.get("clarity_score", "N/A")
        completeness_score = text_analysis.get("completeness_score", "N/A")
        
        content += f"- **æ–‡æœ¬æ¸…æ™°åº¦**: {clarity_score}/10\n"
        content += f"- **æ–‡æœ¬å®Œæ•´æ€§**: {completeness_score}/10\n\n"
        
        issues = text_analysis.get("issues", [])
        if issues:
            content += "### å‘ç°çš„é—®é¢˜\n\n"
            for issue in issues:
                severity_emoji = self._get_severity_emoji(issue.get("severity", "medium"))
                content += f"- {severity_emoji} **{issue.get('type', 'N/A')}**\n"
                content += f"  - ä¸¥é‡ç¨‹åº¦: `{issue.get('severity', 'medium').upper()}`\n"
                content += f"  - æè¿°: {issue.get('description', 'N/A')}\n\n"
        else:
            content += "âœ… æœªå‘ç°æ˜æ˜¾çš„æ–‡æœ¬é—®é¢˜ã€‚\n\n"
        
        content += "---\n\n## ğŸ”§ æŠ€æœ¯å‚æ•°å®¡æŸ¥ (Technical Parameter Review)\n\n"
        
        tech_review = audit_result.get("technical_parameter_review", {})
        
        mentioned = tech_review.get("mentioned_contracts", [])
        if mentioned:
            content += "### æ–‡æœ¬ä¸­æ˜ç¡®æåˆ°çš„åˆçº¦\n\n"
            for addr in mentioned:
                content += f"- `{addr}`\n"
            content += "\n"
        
        unmentioned = tech_review.get("unmentioned_contracts", [])
        if unmentioned:
            content += "### âš ï¸ æœªåœ¨æ–‡æœ¬ä¸­æåˆ°çš„åˆçº¦\n\n"
            for contract in unmentioned:
                risk_emoji = self._get_risk_emoji(contract.get("risk_level", "medium"))
                content += f"- {risk_emoji} **{contract.get('address', 'N/A')}**\n"
                content += f"  - é£é™©ç­‰çº§: `{contract.get('risk_level', 'medium').upper()}`\n"
                content += f"  - è¯´æ˜: {contract.get('description', 'N/A')}\n\n"
        else:
            content += "âœ… æ‰€æœ‰åˆçº¦åœ°å€éƒ½åœ¨æ–‡æœ¬ä¸­æ˜ç¡®æåˆ°ã€‚\n\n"
        
        value_consistency = tech_review.get("value_consistency", {})
        if value_consistency:
            is_consistent = value_consistency.get("is_consistent", True)
            content += f"### ETH è½¬è´¦é‡‘é¢ä¸€è‡´æ€§\n\n"
            content += f"- **ä¸€è‡´æ€§**: {'âœ… æ˜¯' if is_consistent else 'âš ï¸ å¦'}\n"
            content += f"- **è¯´æ˜**: {value_consistency.get('description', 'N/A')}\n\n"
        
        content += "---\n\n## âš ï¸ é£é™©è¯„ä¼° (Risk Assessment)\n\n"
        
        risk_assessment = audit_result.get("risk_assessment", {})
        overall_risk = risk_assessment.get("overall_risk_level", "medium")
        risk_emoji = self._get_risk_emoji(overall_risk)
        
        content += f"### æ€»ä½“é£é™©ç­‰çº§: {risk_emoji} **{overall_risk.upper()}**\n\n"
        
        identified_risks = risk_assessment.get("identified_risks", [])
        if identified_risks:
            for i, risk in enumerate(identified_risks, 1):
                severity_emoji = self._get_severity_emoji(risk.get("severity", "medium"))
                content += f"### {i}. {severity_emoji} {risk.get('type', 'UNKNOWN_RISK')}\n\n"
                content += f"- **ä¸¥é‡ç¨‹åº¦**: `{risk.get('severity', 'medium').upper()}`\n"
                content += f"- **æè¿°**: {risk.get('description', 'N/A')}\n"
                content += f"- **å»ºè®®**: {risk.get('recommendation', 'N/A')}\n\n"
        else:
            content += "âœ… æœªå‘ç°æ˜æ˜¾çš„æ½œåœ¨é£é™©ã€‚\n\n"
        
        content += "---\n\n## âœ… å®Œæ•´æ€§æ£€æŸ¥ (Completeness Check)\n\n"
        
        completeness = audit_result.get("completeness_check", {})
        sufficient = completeness.get("sufficient_for_decision", False)
        
        content += f"- **ä¿¡æ¯æ˜¯å¦å……åˆ†**: {'âœ… æ˜¯' if sufficient else 'âš ï¸ å¦'}\n\n"
        
        missing_info = completeness.get("missing_information", [])
        if missing_info:
            content += "### ç¼ºå¤±çš„ä¿¡æ¯\n\n"
            for info in missing_info:
                importance_emoji = self._get_risk_emoji(info.get("importance", "medium"))
                content += f"- {importance_emoji} **{info.get('type', 'N/A')}**\n"
                content += f"  - é‡è¦æ€§: `{info.get('importance', 'medium').upper()}`\n"
                content += f"  - æè¿°: {info.get('description', 'N/A')}\n\n"
        else:
            content += "âœ… ææ¡ˆæ–‡æœ¬æä¾›äº†å……åˆ†çš„ä¿¡æ¯ã€‚\n\n"
        
        recommendation = completeness.get("recommendation", "N/A")
        content += f"### å»ºè®®\n\n{recommendation}\n\n"
        
        content += "---\n\n## ğŸ”’ å®‰å…¨ç»“è®º\n\n"
        content += f"{audit_result.get('security_conclusion', 'N/A')}\n\n"
        
        content += "---\n\n## ğŸ“ æ€»ç»“\n\n"
        content += f"{audit_result.get('summary', 'N/A')}\n\n"
        
        return content
    
    def _generate_group2_report_content(self, audit_result: Dict[str, Any]) -> str:
        """ç”Ÿæˆç»„2çš„æŠ¥å‘Šå†…å®¹ï¼ˆç±»ä¼¼æ ‡å‡†å®¡è®¡æ ¼å¼ï¼‰"""
        content = "## ğŸ” å†²çªæ£€æµ‹ (Conflict Detection)\n\n"
        
        conflict_detection = audit_result.get("conflict_detection", {})
        
        # ç³»ç»Ÿçº§è°ƒç”¨
        system_calls = conflict_detection.get("system_level_calls", [])
        if system_calls:
            content += "### ç³»ç»Ÿçº§å¸¸è§„è°ƒç”¨\n\n"
            content += "ä»¥ä¸‹åœ°å€å±äºç³»ç»Ÿçº§åˆçº¦ï¼Œå±äºæ­£å¸¸è°ƒç”¨ï¼Œæ— éœ€åœ¨ææ¡ˆæ–‡æœ¬ä¸­ç‰¹åˆ«è¯´æ˜ï¼š\n\n"
            for call in system_calls:
                content += f"- âœ… **{call.get('address', 'N/A')}**\n"
                content += f"  - ç±»å‹: `{call.get('type', 'N/A')}`\n"
                content += f"  - è¯´æ˜: {call.get('description', 'N/A')}\n\n"
        
        # æœªæŠ«éœ²çš„ç¬¬ä¸‰æ–¹åœ°å€ï¼ˆéç³»ç»Ÿçº§ï¼‰
        unaccounted = conflict_detection.get("unaccounted_contracts", [])
        non_system_unaccounted = [
            c for c in unaccounted 
            if not c.get("is_system_contract", False) and 
               c.get("contract_type") != "SYSTEM_LEVEL_CALL"
        ]
        
        if non_system_unaccounted:
            content += "### âš ï¸ æœªå…¬å¼€çš„ç¬¬ä¸‰æ–¹åˆçº¦åœ°å€\n\n"
            content += "ä»¥ä¸‹åœ°å€æœªåœ¨ææ¡ˆæ–‡æœ¬ä¸­æ˜ç¡®æåˆ°ï¼Œä¸”ä¸å±äºç³»ç»Ÿçº§åˆçº¦ï¼Œéœ€è¦è¿›ä¸€æ­¥å®¡æŸ¥ï¼š\n\n"
            for contract in non_system_unaccounted:
                risk_emoji = self._get_risk_emoji(contract.get("risk_level", "medium"))
                content += f"- {risk_emoji} **{contract.get('address', 'N/A')}**\n"
                content += f"  - é£é™©ç­‰çº§: `{contract.get('risk_level', 'medium').upper()}`\n"
                content += f"  - è¯´æ˜: {contract.get('description', 'N/A')}\n\n"
        elif not system_calls:
            content += "âœ… æœªå‘ç°æœªå…¬å¼€çš„åˆçº¦åœ°å€ã€‚\n\n"
        
        mentioned = conflict_detection.get("mentioned_contracts", [])
        if mentioned:
            content += "### æ–‡æœ¬ä¸­æ˜ç¡®æåˆ°çš„åˆçº¦\n\n"
            for addr in mentioned:
                content += f"- `{addr}`\n"
            content += "\n"
        
        content += "---\n\n## ğŸ“ æ·±åº¦åˆ†æ (Depth Analysis)\n\n"
        
        depth_analysis = audit_result.get("depth_analysis", {})
        claimed = depth_analysis.get("claimed_complexity", "N/A")
        actual_depth = depth_analysis.get("actual_depth", "N/A")
        mismatch = depth_analysis.get("depth_mismatch", False)
        
        content += f"- **æ–‡æœ¬å£°ç§°çš„å¤æ‚åº¦**: {claimed}\n"
        content += f"- **å®é™…æ‰§è¡Œæ·±åº¦**: {actual_depth}\n"
        content += f"- **æ·±åº¦ä¸åŒ¹é…**: {'âš ï¸ æ˜¯' if mismatch else 'âœ… å¦'}\n\n"
        
        if mismatch:
            risk_assessment = depth_analysis.get("risk_assessment", "N/A")
            content += f"**é£é™©è¯„ä¼°**: {risk_assessment}\n\n"
        
        content += "---\n\n## ğŸ”— å‡½æ•°è¯­ä¹‰åŒ¹é… (Function Semantic Match)\n\n"
        
        func_match = audit_result.get("function_semantic_match", {})
        
        matched = func_match.get("matched_functions", [])
        if matched:
            content += "### âœ… åŒ¹é…çš„å‡½æ•°\n\n"
            for func in matched:
                content += f"- **{func.get('function', 'N/A')}**: {func.get('description', 'N/A')}\n"
            content += "\n"
        
        unmatched = func_match.get("unmatched_functions", [])
        if unmatched:
            content += "### âš ï¸ ä¸åŒ¹é…çš„å‡½æ•°\n\n"
            for func in unmatched:
                risk_emoji = self._get_risk_emoji(func.get("risk_level", "medium"))
                content += f"- {risk_emoji} **{func.get('function', 'N/A')}**\n"
                content += f"  - é£é™©ç­‰çº§: `{func.get('risk_level', 'medium').upper()}`\n"
                content += f"  - è¯´æ˜: {func.get('description', 'N/A')}\n\n"
        else:
            content += "âœ… æ‰€æœ‰å‡½æ•°è°ƒç”¨ä¸æ–‡æœ¬æè¿°åŒ¹é…ã€‚\n\n"
        
        content += "---\n\n## âš ï¸ æ½œåœ¨é£é™©ç‚¹\n\n"
        
        risks = audit_result.get("potential_risks", [])
        if risks:
            for i, risk in enumerate(risks, 1):
                severity_emoji = self._get_severity_emoji(risk.get("severity", "medium"))
                content += f"### {i}. {severity_emoji} {risk.get('type', 'UNKNOWN_RISK')}\n\n"
                content += f"- **ä¸¥é‡ç¨‹åº¦**: `{risk.get('severity', 'medium').upper()}`\n"
                content += f"- **æè¿°**: {risk.get('description', 'N/A')}\n"
                content += f"- **å»ºè®®**: {risk.get('recommendation', 'N/A')}\n\n"
        else:
            content += "âœ… æœªå‘ç°æ˜æ˜¾çš„æ½œåœ¨é£é™©ã€‚\n\n"
        
        content += "---\n\n## ğŸ”’ å®‰å…¨ç»“è®º\n\n"
        content += f"{audit_result.get('security_conclusion', 'N/A')}\n\n"
        
        content += "---\n\n## ğŸ“ æ€»ç»“\n\n"
        content += f"{audit_result.get('summary', 'N/A')}\n\n"
        
        return content
    
    def _get_score_description(self, score: int) -> str:
        """è·å–è¯„åˆ†æè¿°"""
        if score >= 9:
            return "âœ… **ä¼˜ç§€**: ææ¡ˆæ–‡æœ¬ä¸æ‰§è¡Œè½¨è¿¹é«˜åº¦ä¸€è‡´ï¼Œæ— æ˜æ˜¾é£é™©ã€‚"
        elif score >= 7:
            return "âœ… **è‰¯å¥½**: ææ¡ˆæ–‡æœ¬ä¸æ‰§è¡Œè½¨è¿¹åŸºæœ¬ä¸€è‡´ï¼Œå­˜åœ¨å°‘é‡å¯æ¥å—çš„å·®å¼‚ã€‚"
        elif score >= 5:
            return "âš ï¸ **ä¸­ç­‰**: ææ¡ˆæ–‡æœ¬ä¸æ‰§è¡Œè½¨è¿¹å­˜åœ¨ä¸€å®šå·®å¼‚ï¼Œéœ€è¦è¿›ä¸€æ­¥å®¡æŸ¥ã€‚"
        elif score >= 3:
            return "âš ï¸ **è¾ƒå·®**: ææ¡ˆæ–‡æœ¬ä¸æ‰§è¡Œè½¨è¿¹å­˜åœ¨æ˜æ˜¾å·®å¼‚ï¼Œå­˜åœ¨æ½œåœ¨é£é™©ã€‚"
        else:
            return "âŒ **ä¸¥é‡**: ææ¡ˆæ–‡æœ¬ä¸æ‰§è¡Œè½¨è¿¹ä¸¥é‡ä¸ä¸€è‡´ï¼Œå­˜åœ¨é«˜é£é™©ã€‚"
    
    def _get_risk_emoji(self, risk_level: str) -> str:
        """è·å–é£é™©ç­‰çº§ emoji"""
        level_map = {
            "low": "ğŸŸ¢",
            "medium": "ğŸŸ¡",
            "high": "ğŸŸ ",
            "critical": "ğŸ”´"
        }
        return level_map.get(risk_level.lower(), "âšª")
    
    def _get_severity_emoji(self, severity: str) -> str:
        """è·å–ä¸¥é‡ç¨‹åº¦ emoji"""
        return self._get_risk_emoji(severity)
    
    def audit_group1(self,
                     proposal_path: str = "data/proposals/collected_proposal.json",
                     output_path: str = "outputs/reports/ablation_group1_report.md") -> Dict[str, Any]:
        """
        æ‰§è¡Œç»„1çš„å®¡è®¡æµç¨‹ï¼ˆä»…ææ¡ˆæ–‡æœ¬ï¼‰
        
        Args:
            proposal_path: ææ¡ˆæ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºæŠ¥å‘Šè·¯å¾„
            
        Returns:
            å®¡è®¡ç»“æœå­—å…¸
        """
        logger.info("Starting ablation audit group 1 (proposal text only)")
        
        # 1. åŠ è½½æ•°æ®
        proposal_data = self.load_proposal(proposal_path)
        proposal_description = proposal_data.get("description", "")
        proposal_id = str(proposal_data.get("id", "N/A"))
        
        # 2. æ„å»º Promptï¼ˆç»„1ï¼‰
        prompt = self.build_audit_prompt_group1(proposal_description, proposal_data)
        
        # 3. è°ƒç”¨ LLM
        logger.info("Calling LLM for ablation audit group 1")
        system_prompt = "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ™ºèƒ½åˆçº¦å®‰å…¨å®¡è®¡ä¸“å®¶ï¼Œæ“…é•¿åˆ†æ DAO ææ¡ˆçš„ä¸€è‡´æ€§å’Œå®‰å…¨æ€§ã€‚æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªæ¶ˆèå®éªŒç»„1ï¼Œä»…åŸºäºææ¡ˆæ–‡æœ¬è¿›è¡Œåˆ†æï¼Œä¸åŒ…å«æ‰§è¡Œè½¨è¿¹ä¿¡æ¯ã€‚"
        
        try:
            response = self.llm.call(prompt, system_prompt=system_prompt)
            logger.info("LLM response received")
        except Exception as e:
            logger.error(f"Error calling LLM: {e}")
            raise
        
        # 4. è§£æå“åº”
        audit_result = self.parse_llm_response(response)
        audit_result["proposal_id"] = proposal_id
        audit_result["experiment_type"] = "ablation_group1_text_only"
        
        # 5. ç”ŸæˆæŠ¥å‘Š
        markdown_report = self.generate_markdown_report(audit_result, proposal_id, group=1)
        
        # 6. ä¿å­˜æŠ¥å‘Š
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"Saving ablation audit group 1 report to {output_file}")
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(markdown_report)
        
        logger.info("Ablation audit group 1 completed")
        
        return audit_result
    
    def audit_group2(self,
                     proposal_path: str = "data/proposals/collected_proposal.json",
                     trace_path: str = "data/traces/trace_report.json",
                     output_path: str = "outputs/reports/ablation_group2_report.md") -> Dict[str, Any]:
        """
        æ‰§è¡Œç»„2çš„å®¡è®¡æµç¨‹ï¼ˆææ¡ˆæ–‡æœ¬ + åŸå§‹ JSON Traceï¼‰
        
        Args:
            proposal_path: ææ¡ˆæ–‡ä»¶è·¯å¾„
            trace_path: Trace æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºæŠ¥å‘Šè·¯å¾„
            
        Returns:
            å®¡è®¡ç»“æœå­—å…¸
        """
        logger.info("Starting ablation audit group 2 (proposal text + raw JSON trace)")
        
        # 1. åŠ è½½æ•°æ®
        proposal_data = self.load_proposal(proposal_path)
        proposal_description = proposal_data.get("description", "")
        proposal_id = str(proposal_data.get("id", "N/A"))
        
        trace_data = self.load_trace_report(trace_path)
        
        # 2. æ„å»º Promptï¼ˆç»„2ï¼‰
        prompt = self.build_audit_prompt_group2(proposal_description, proposal_data, trace_data)
        
        # 3. è°ƒç”¨ LLM
        logger.info("Calling LLM for ablation audit group 2")
        system_prompt = "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ™ºèƒ½åˆçº¦å®‰å…¨å®¡è®¡ä¸“å®¶ï¼Œæ“…é•¿åˆ†æ DAO ææ¡ˆçš„ä¸€è‡´æ€§å’Œå®‰å…¨æ€§ã€‚æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªæ¶ˆèå®éªŒç»„2ï¼Œä½¿ç”¨ææ¡ˆæ–‡æœ¬å’ŒåŸå§‹ JSON Trace æ•°æ®è¿›è¡Œåˆ†æï¼Œä½†ä¸ä½¿ç”¨å›¾ç»“æ„ã€‚"
        
        try:
            response = self.llm.call(prompt, system_prompt=system_prompt)
            logger.info("LLM response received")
        except Exception as e:
            logger.error(f"Error calling LLM: {e}")
            raise
        
        # 4. è§£æå“åº”
        audit_result = self.parse_llm_response(response)
        audit_result["proposal_id"] = proposal_id
        audit_result["experiment_type"] = "ablation_group2_text_trace"
        
        # 5. ç”ŸæˆæŠ¥å‘Š
        markdown_report = self.generate_markdown_report(audit_result, proposal_id, group=2)
        
        # 6. ä¿å­˜æŠ¥å‘Š
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"Saving ablation audit group 2 report to {output_file}")
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(markdown_report)
        
        logger.info("Ablation audit group 2 completed")
        
        return audit_result


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="DAO ææ¡ˆå®¡è®¡å·¥å…·ï¼ˆæ¶ˆèå®éªŒï¼‰")
    parser.add_argument(
        "--group",
        type=int,
        choices=[1, 2],
        required=True,
        help="å®éªŒç»„ç¼–å·ï¼š1=ä»…ææ¡ˆæ–‡æœ¬ï¼Œ2=ææ¡ˆæ–‡æœ¬+åŸå§‹JSON Trace"
    )
    parser.add_argument(
        "--proposal",
        type=str,
        default="data/proposals/collected_proposal.json",
        help="ææ¡ˆ JSON æ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--trace",
        type=str,
        default="data/traces/trace_report.json",
        help="Trace JSON æ–‡ä»¶è·¯å¾„ï¼ˆç»„2éœ€è¦ï¼‰"
    )
    parser.add_argument(
        "--output",
        type=str,
        default=None,
        help="è¾“å‡ºæŠ¥å‘Šè·¯å¾„ï¼ˆå¦‚æœä¸æä¾›ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„ï¼‰"
    )
    parser.add_argument(
        "--llm-type",
        type=str,
        choices=["anthropic", "openai"],
        default="anthropic",
        help="LLM ç±»å‹"
    )
    parser.add_argument(
        "--api-key",
        type=str,
        default=None,
        help="API Keyï¼ˆå¦‚æœä¸æä¾›ï¼Œä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰"
    )
    parser.add_argument(
        "--model",
        type=str,
        default=None,
        help="æ¨¡å‹åç§°ï¼ˆå¦‚æœä¸æä¾›ï¼Œä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰"
    )
    parser.add_argument(
        "--base-url",
        type=str,
        default=None,
        help="è‡ªå®šä¹‰ API åŸºç¡€ URLï¼ˆç”¨äºç¬¬ä¸‰æ–¹å¹³å°ï¼‰"
    )
    
    args = parser.parse_args()
    
    # åˆ›å»ºæ¶ˆèå®éªŒå®¡è®¡å™¨
    auditor = AblationAuditor(
        llm_type=args.llm_type,
        api_key=args.api_key,
        model=args.model,
        base_url=args.base_url
    )
    
    # æ ¹æ®ç»„åˆ«æ‰§è¡Œå®¡è®¡
    if args.group == 1:
        output_path = args.output or "outputs/reports/ablation_group1_report.md"
        result = auditor.audit_group1(
            proposal_path=args.proposal,
            output_path=output_path
        )
        print(f"\nâœ… æ¶ˆèå®éªŒç»„1å®¡è®¡å®Œæˆï¼")
        print(f"ä¸€è‡´æ€§è¯„åˆ†: {result.get('consistency_score', 'N/A')}/10")
        print(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
        print(f"\nâš ï¸  æ³¨æ„ï¼šè¿™æ˜¯æ¶ˆèå®éªŒç»„1ï¼Œä»…ä½¿ç”¨ææ¡ˆæ–‡æœ¬ã€‚")
    else:
        output_path = args.output or "outputs/reports/ablation_group2_report.md"
        result = auditor.audit_group2(
            proposal_path=args.proposal,
            trace_path=args.trace,
            output_path=output_path
        )
        print(f"\nâœ… æ¶ˆèå®éªŒç»„2å®¡è®¡å®Œæˆï¼")
        print(f"ä¸€è‡´æ€§è¯„åˆ†: {result.get('consistency_score', 'N/A')}/10")
        print(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
        print(f"\nâš ï¸  æ³¨æ„ï¼šè¿™æ˜¯æ¶ˆèå®éªŒç»„2ï¼Œä½¿ç”¨ææ¡ˆæ–‡æœ¬å’ŒåŸå§‹ JSON Traceï¼Œä½†ä¸ä½¿ç”¨å›¾ç»“æ„ã€‚")


if __name__ == "__main__":
    main()
