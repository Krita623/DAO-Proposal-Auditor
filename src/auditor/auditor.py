#!/usr/bin/env python3
"""
Auditor - ææ¡ˆå®¡è®¡å™¨

åŠŸèƒ½ï¼š
1. è¯»å–ææ¡ˆæ–‡æœ¬å’Œå›¾æè¿°
2. ä½¿ç”¨ LLM è¿›è¡Œä¸€è‡´æ€§åˆ†æ
3. ç”Ÿæˆæ ¼å¼åŒ–çš„å®¡è®¡æŠ¥å‘Š
"""

import json
import re
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime

from loguru import logger
from dotenv import load_dotenv
import os

# å°è¯•å¯¼å…¥ LLM åº“
try:
    from langchain_anthropic import ChatAnthropic
    from langchain_openai import ChatOpenAI
    from langchain_core.messages import HumanMessage, SystemMessage
    LANGCHAIN_AVAILABLE = True
except ImportError:
    LANGCHAIN_AVAILABLE = False
    logger.warning("LangChain not available, will use direct API calls")

try:
    import requests
    REQUESTS_AVAILABLE = True
except ImportError:
    REQUESTS_AVAILABLE = False
    logger.warning("requests not available")

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


# ç³»ç»Ÿåˆçº¦åœ°å€åˆ—è¡¨ï¼ˆå¸¸è¯†æ£€æŸ¥ï¼‰
SYSTEM_CONTRACTS = {
    # ä»¥å¤ªåŠé¢„ç¼–è¯‘åˆçº¦ (0x1-0x9)
    "0x0000000000000000000000000000000000000001": "Ethereum Precompile: ECRecover",
    "0x0000000000000000000000000000000000000002": "Ethereum Precompile: SHA256",
    "0x0000000000000000000000000000000000000003": "Ethereum Precompile: RIPEMD160",
    "0x0000000000000000000000000000000000000004": "Ethereum Precompile: Identity",
    "0x0000000000000000000000000000000000000005": "Ethereum Precompile: ModExp",
    "0x0000000000000000000000000000000000000006": "Ethereum Precompile: BN256Add",
    "0x0000000000000000000000000000000000000007": "Ethereum Precompile: BN256Mul",
    "0x0000000000000000000000000000000000000008": "Ethereum Precompile: BN256Pairing",
    "0x0000000000000000000000000000000000000009": "Ethereum Precompile: Blake2F",
    
    # Arbitrum ç³»ç»Ÿåˆçº¦
    "0x0000000000000000000000000000000000000064": "Arbitrum System Contract: L1 ArbSys",
    "0x0000000000000000000000000000000000000065": "Arbitrum System Contract: L2 ArbSys",
    
    # å…¶ä»–å¸¸è§çš„ç³»ç»Ÿåˆçº¦åœ°å€ï¼ˆå¯æ ¹æ®éœ€è¦æ‰©å±•ï¼‰
    # "0x...": "Description",
}

# ä»£ç†åˆçº¦æ¨¡å¼è¯†åˆ«ï¼ˆé€šè¿‡å‡½æ•°ç­¾åï¼‰
PROXY_PATTERNS = [
    "delegatecall",
    "implementation",
    "upgradeTo",
    "upgradeToAndCall",
    "changeAdmin",
    "admin",
    "proxy",
]


def is_system_contract(address: str) -> bool:
    """
    æ£€æŸ¥åœ°å€æ˜¯å¦ä¸ºç³»ç»Ÿåˆçº¦
    
    Args:
        address: åˆçº¦åœ°å€ï¼ˆå°å†™æˆ–æ··åˆå¤§å°å†™ï¼‰
        
    Returns:
        æ˜¯å¦ä¸ºç³»ç»Ÿåˆçº¦
    """
    addr_lower = address.lower()
    
    # æ£€æŸ¥é¢„ç¼–è¯‘åˆçº¦ (0x1-0x9)
    if addr_lower.startswith("0x000000000000000000000000000000000000000"):
        last_char = addr_lower[-1]
        if last_char in "123456789":
            return True
    
    # æ£€æŸ¥ç³»ç»Ÿåˆçº¦åˆ—è¡¨
    if addr_lower in SYSTEM_CONTRACTS:
        return True
    
    return False


def get_system_contract_description(address: str) -> Optional[str]:
    """
    è·å–ç³»ç»Ÿåˆçº¦æè¿°
    
    Args:
        address: åˆçº¦åœ°å€
        
    Returns:
        ç³»ç»Ÿåˆçº¦æè¿°ï¼Œå¦‚æœä¸æ˜¯ç³»ç»Ÿåˆçº¦åˆ™è¿”å› None
    """
    return SYSTEM_CONTRACTS.get(address.lower())


class LLMClient:
    """LLM å®¢æˆ·ç«¯æŠ½è±¡ç±»"""
    
    def call(self, prompt: str, system_prompt: Optional[str] = None) -> str:
        """
        è°ƒç”¨ LLM API
        
        Args:
            prompt: ç”¨æˆ·æç¤ºè¯
            system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            LLM å“åº”æ–‡æœ¬
        """
        raise NotImplementedError


class AnthropicClient(LLMClient):
    """Anthropic Claude API å®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: Optional[str] = None, model: str = "claude-3-5-sonnet-20241022", 
                 base_url: Optional[str] = None):
        """
        åˆå§‹åŒ– Anthropic å®¢æˆ·ç«¯
        
        Args:
            api_key: API Keyï¼ˆå¦‚æœä¸º Noneï¼Œä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
            model: æ¨¡å‹åç§°
            base_url: è‡ªå®šä¹‰ API åŸºç¡€ URLï¼ˆç”¨äºç¬¬ä¸‰æ–¹å¹³å°ï¼‰
        """
        self.api_key = api_key or os.getenv("ANTHROPIC_API_KEY")
        self.model = model
        self.base_url = base_url or os.getenv("ANTHROPIC_BASE_URL")
        
        if not self.api_key:
            raise ValueError("ANTHROPIC_API_KEY not found in environment variables")
        
        if LANGCHAIN_AVAILABLE and not self.base_url:
            # ä½¿ç”¨ LangChainï¼ˆæ ‡å‡† APIï¼‰
            self.client = ChatAnthropic(
                anthropic_api_key=self.api_key,
                model_name=self.model,
                temperature=0.1,
                max_tokens=4096
            )
            self.use_langchain = True
        else:
            # ä½¿ç”¨ç›´æ¥ API è°ƒç”¨ï¼ˆæ”¯æŒç¬¬ä¸‰æ–¹å¹³å°ï¼‰
            self.use_langchain = False
            if self.base_url:
                # ç¬¬ä¸‰æ–¹å¹³å°ï¼šç¡®ä¿ URL æ ¼å¼æ­£ç¡®
                base = self.base_url.rstrip("/")
                # å¦‚æœ base_url å·²ç»åŒ…å«å®Œæ•´è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™æ·»åŠ  /v1/messages
                if "/v1/messages" in base or "/messages" in base:
                    self.api_url = base
                else:
                    self.api_url = f"{base}/v1/messages"
            else:
                self.api_url = "https://api.anthropic.com/v1/messages"
    
    def call(self, prompt: str, system_prompt: Optional[str] = None) -> str:
        """è°ƒç”¨ Claude API"""
        if self.use_langchain:
            messages = []
            if system_prompt:
                messages.append(SystemMessage(content=system_prompt))
            messages.append(HumanMessage(content=prompt))
            
            response = self.client.invoke(messages)
            return response.content
        else:
            # ç›´æ¥ API è°ƒç”¨ï¼ˆæ”¯æŒç¬¬ä¸‰æ–¹å¹³å°ï¼‰
            headers = {
                "x-api-key": self.api_key,
                "anthropic-version": "2023-06-01",
                "content-type": "application/json"
            }
            
            payload = {
                "model": self.model,
                "max_tokens": 4096,
                "temperature": 0.1,
                "messages": [
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            }
            
            if system_prompt:
                payload["system"] = system_prompt
            
            logger.debug(f"Calling Anthropic API: {self.api_url}")
            logger.debug(f"Headers: {list(headers.keys())}")
            
            try:
                response = requests.post(self.api_url, headers=headers, json=payload, timeout=60)
                response.raise_for_status()
                result = response.json()
                
                # æå–æ–‡æœ¬å†…å®¹
                if "content" in result and len(result["content"]) > 0:
                    return result["content"][0].get("text", "")
                return ""
            except requests.exceptions.HTTPError as e:
                logger.error(f"HTTP Error: {e}")
                logger.error(f"Response status: {response.status_code}")
                logger.error(f"Response body: {response.text[:500]}")
                raise
            except Exception as e:
                logger.error(f"Error calling API: {e}")
                raise


class OpenAIClient(LLMClient):
    """OpenAI API å®¢æˆ·ç«¯ï¼ˆä¹Ÿæ”¯æŒå…¼å®¹ OpenAI æ ¼å¼çš„ç¬¬ä¸‰æ–¹å¹³å°ï¼‰"""
    
    def __init__(self, api_key: Optional[str] = None, model: str = "gpt-4", 
                 base_url: Optional[str] = None):
        """
        åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
        
        Args:
            api_key: API Key
            model: æ¨¡å‹åç§°
            base_url: è‡ªå®šä¹‰ API åŸºç¡€ URLï¼ˆç”¨äºç¬¬ä¸‰æ–¹å¹³å°ï¼‰
        """
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        self.model = model
        self.base_url = base_url or os.getenv("OPENAI_BASE_URL")
        
        if not self.api_key:
            raise ValueError("OPENAI_API_KEY not found in environment variables")
        
        if LANGCHAIN_AVAILABLE and not self.base_url:
            # ä½¿ç”¨ LangChainï¼ˆæ ‡å‡† APIï¼‰
            self.client = ChatOpenAI(
                openai_api_key=self.api_key,
                model_name=self.model,
                temperature=0.1,
                max_tokens=4096
            )
            self.use_langchain = True
        else:
            # ä½¿ç”¨ç›´æ¥ API è°ƒç”¨ï¼ˆæ”¯æŒç¬¬ä¸‰æ–¹å¹³å°ï¼‰
            self.use_langchain = False
            if self.base_url:
                # ç¬¬ä¸‰æ–¹å¹³å°ï¼šç¡®ä¿ URL æ ¼å¼æ­£ç¡®
                base = self.base_url.rstrip("/")
                # å¦‚æœ base_url å·²ç»åŒ…å«å®Œæ•´è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™æ·»åŠ  /chat/completions
                if "/chat/completions" in base or "/v1/chat/completions" in base:
                    self.api_url = base
                elif "/v1" in base:
                    self.api_url = f"{base}/chat/completions"
                else:
                    self.api_url = f"{base}/v1/chat/completions"
            else:
                self.api_url = "https://api.openai.com/v1/chat/completions"
    
    def call(self, prompt: str, system_prompt: Optional[str] = None) -> str:
        """è°ƒç”¨ OpenAI API"""
        if self.use_langchain:
            messages = []
            if system_prompt:
                messages.append(SystemMessage(content=system_prompt))
            messages.append(HumanMessage(content=prompt))
            
            response = self.client.invoke(messages)
            return response.content
        else:
            # ç›´æ¥ API è°ƒç”¨ï¼ˆæ”¯æŒç¬¬ä¸‰æ–¹å¹³å°ï¼‰
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            messages = []
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            messages.append({"role": "user", "content": prompt})
            
            payload = {
                "model": self.model,
                "messages": messages,
                "temperature": 0.1,
                "max_tokens": 4096
            }
            
            response = requests.post(self.api_url, headers=headers, json=payload)
            response.raise_for_status()
            result = response.json()
            
            if "choices" in result and len(result["choices"]) > 0:
                return result["choices"][0]["message"]["content"]
            return ""


class Auditor:
    """ææ¡ˆå®¡è®¡å™¨"""
    
    def __init__(self, 
                 llm_client: Optional[LLMClient] = None,
                 llm_type: str = "anthropic",
                 api_key: Optional[str] = None,
                 model: Optional[str] = None,
                 base_url: Optional[str] = None):
        """
        åˆå§‹åŒ–å®¡è®¡å™¨
        
        Args:
            llm_client: è‡ªå®šä¹‰ LLM å®¢æˆ·ç«¯ï¼ˆå¦‚æœæä¾›ï¼Œå°†ä½¿ç”¨æ­¤å®¢æˆ·ç«¯ï¼‰
            llm_type: LLM ç±»å‹ ("anthropic" æˆ– "openai")
            api_key: API Keyï¼ˆå¦‚æœä¸º Noneï¼Œä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
            model: æ¨¡å‹åç§°ï¼ˆå¦‚æœä¸º Noneï¼Œä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
            base_url: è‡ªå®šä¹‰ API åŸºç¡€ URLï¼ˆç”¨äºç¬¬ä¸‰æ–¹å¹³å°ï¼‰
        """
        if llm_client:
            self.llm = llm_client
        else:
            if llm_type.lower() == "anthropic":
                model = model or os.getenv("LLM_MODEL", "claude-3-5-sonnet-20241022")
                self.llm = AnthropicClient(api_key=api_key, model=model, base_url=base_url)
            elif llm_type.lower() == "openai":
                model = model or os.getenv("LLM_MODEL", "gpt-4")
                self.llm = OpenAIClient(api_key=api_key, model=model, base_url=base_url)
            else:
                raise ValueError(f"Unsupported LLM type: {llm_type}")
    
    def load_proposal(self, proposal_path: str) -> Dict[str, Any]:
        """
        åŠ è½½ææ¡ˆæ•°æ®
        
        Args:
            proposal_path: ææ¡ˆ JSON æ–‡ä»¶è·¯å¾„
            
        Returns:
            ææ¡ˆæ•°æ®å­—å…¸
        """
        proposal_file = Path(proposal_path)
        if not proposal_file.exists():
            raise FileNotFoundError(f"Proposal file not found: {proposal_path}")
        
        logger.info(f"Loading proposal from {proposal_file}")
        with open(proposal_file, 'r', encoding='utf-8') as f:
            proposal_data = json.load(f)
        
        return proposal_data
    
    def load_graph_description(self, graph_desc_path: str) -> str:
        """
        åŠ è½½å›¾æè¿°æ–‡æœ¬
        
        Args:
            graph_desc_path: å›¾æè¿°æ–‡ä»¶è·¯å¾„
            
        Returns:
            å›¾æè¿°æ–‡æœ¬
        """
        desc_file = Path(graph_desc_path)
        if not desc_file.exists():
            raise FileNotFoundError(f"Graph description file not found: {graph_desc_path}")
        
        logger.info(f"Loading graph description from {desc_file}")
        with open(desc_file, 'r', encoding='utf-8') as f:
            description = f.read()
        
        return description
    
    def build_audit_prompt(self, proposal_description: str, graph_description: str) -> str:
        """
        æ„å»ºå®¡è®¡ Prompt
        
        Args:
            proposal_description: ææ¡ˆæ–‡æœ¬æè¿°
            graph_description: å›¾æè¿°æ–‡æœ¬
            
        Returns:
            å®Œæ•´çš„å®¡è®¡ Prompt
        """
        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ™ºèƒ½åˆçº¦å®‰å…¨å®¡è®¡ä¸“å®¶ã€‚è¯·å¯¹ä»¥ä¸‹ DAO ææ¡ˆè¿›è¡Œæ·±åº¦å®¡è®¡åˆ†æã€‚

## ä»»åŠ¡è¯´æ˜

ä½ éœ€è¦æ‰§è¡Œä»¥ä¸‹ä¸‰ä¸ªæ ¸å¿ƒå®¡è®¡ä»»åŠ¡ï¼š

### 1. [Conflict Detection] å†²çªæ£€æµ‹ï¼ˆå«å¸¸è¯†æ£€æŸ¥ï¼‰
æ£€æŸ¥å®é™…æ‰§è¡Œçš„èŠ‚ç‚¹ï¼ˆåˆçº¦åœ°å€ï¼‰æ˜¯å¦åœ¨ææ¡ˆæ–‡æœ¬ä¸­æ˜ç¡®æåˆ°ã€‚

**é‡è¦ï¼šå¸¸è¯†æ£€æŸ¥è§„åˆ™**
- å¦‚æœå›¾ä¸­å‡ºç°çš„åœ°å€å±äºä»¥ä¸‹ç±»å‹ï¼Œ**ä¸åº”è§†ä¸ºæœªæŠ«éœ²é£é™©**ï¼Œè€Œåº”æ ‡è®°ä¸º `SYSTEM_LEVEL_CALL`ï¼ˆç³»ç»Ÿçº§å¸¸è§„è°ƒç”¨ï¼‰ï¼š
  1. **ä»¥å¤ªåŠé¢„ç¼–è¯‘åˆçº¦**ï¼šåœ°å€èŒƒå›´ 0x1-0x9ï¼ˆå¦‚ 0x0000000000000000000000000000000000000001ï¼‰
  2. **L2 ç³»ç»Ÿåˆçº¦**ï¼šå¦‚ Arbitrum çš„ 0x64ï¼ˆL1 ArbSysï¼‰ã€0x65ï¼ˆL2 ArbSysï¼‰ç­‰
  3. **æ ‡å‡†ä»£ç†è½¬å‘é€»è¾‘**ï¼šé€šè¿‡ DELEGATECALL å®ç°çš„ä»£ç†æ¨¡å¼ï¼ˆå¦‚ EIP-1967 ä»£ç†ã€UUPS ä»£ç†ç­‰ï¼‰

- **é‡ç‚¹å…³æ³¨**ï¼šåªæœ‰é‚£äº›**éç³»ç»Ÿçº§**ã€ä¸”**æœªåœ¨æ–‡æœ¬ä¸­è§£é‡Šç”¨é€”**çš„ç¬¬ä¸‰æ–¹åœ°å€ï¼Œæ‰åº”æ ‡è®°ä¸º `UNACCOUNTED_CONTRACT`ï¼ˆæœªæŠ«éœ²é£é™©ï¼‰ã€‚

**ç³»ç»Ÿåˆçº¦åœ°å€å‚è€ƒ**ï¼š
- **ä»¥å¤ªåŠé¢„ç¼–è¯‘åˆçº¦**ï¼ˆåœ°å€æ ¼å¼ï¼š0x000000000000000000000000000000000000000Xï¼ŒX=1-9ï¼‰ï¼š
  - 0x1: ECRecoverï¼ˆæ¤­åœ†æ›²çº¿ç­¾åéªŒè¯ï¼‰
  - 0x2: SHA256ï¼ˆå“ˆå¸Œè®¡ç®—ï¼‰
  - 0x3: RIPEMD160ï¼ˆå“ˆå¸Œè®¡ç®—ï¼‰
  - 0x4: Identityï¼ˆæ•°æ®å¤åˆ¶ï¼‰
  - 0x5: ModExpï¼ˆæ¨¡å¹‚è¿ç®—ï¼‰
  - 0x6-0x9: BN256 æ¤­åœ†æ›²çº¿è¿ç®—ã€Blake2F å“ˆå¸Œ
- **Arbitrum L2 ç³»ç»Ÿåˆçº¦**ï¼š
  - 0x64 (0x0000000000000000000000000000000000000064): L1 ArbSysï¼ˆL1 ç³»ç»Ÿè°ƒç”¨æ¥å£ï¼‰
  - 0x65 (0x0000000000000000000000000000000000000065): L2 ArbSysï¼ˆL2 ç³»ç»Ÿè°ƒç”¨æ¥å£ï¼‰
- **ä»£ç†è½¬å‘æ¨¡å¼**ï¼šå¦‚æœè°ƒç”¨é“¾ä¸­åŒ…å« DELEGATECALL ä¸”ç›®æ ‡åœ°å€æ˜¯å·²çŸ¥çš„ä»£ç†å®ç°åˆçº¦ï¼ˆå¦‚ EIP-1967ã€UUPS ç­‰æ ‡å‡†ä»£ç†ï¼‰ï¼Œåº”è§†ä¸ºç³»ç»Ÿçº§è°ƒç”¨ã€‚

**åˆ¤æ–­æ ‡å‡†**ï¼š
1. å¦‚æœåœ°å€åŒ¹é…ä¸Šè¿°ç³»ç»Ÿåˆçº¦ï¼Œæ ‡è®°ä¸º `SYSTEM_LEVEL_CALL`ï¼Œ`is_system_contract: true`
2. å¦‚æœåœ°å€æœªåœ¨æ–‡æœ¬ä¸­æåˆ°ï¼Œä½†å±äºä»£ç†è½¬å‘é€»è¾‘ï¼ˆé€šè¿‡ DELEGATECALL è°ƒç”¨æ ‡å‡†ä»£ç†å®ç°ï¼‰ï¼Œæ ‡è®°ä¸º `SYSTEM_LEVEL_CALL`
3. åªæœ‰é‚£äº›**æ—¢ä¸æ˜¯ç³»ç»Ÿåˆçº¦ï¼Œä¹Ÿä¸æ˜¯æ ‡å‡†ä»£ç†æ¨¡å¼ï¼Œä¸”æœªåœ¨æ–‡æœ¬ä¸­è¯´æ˜**çš„åœ°å€ï¼Œæ‰æ ‡è®°ä¸º `UNACCOUNTED_CONTRACT`ï¼Œ`is_system_contract: false`

### 2. [Depth Analysis] æ·±åº¦åˆ†æ
å¦‚æœææ¡ˆæ–‡æœ¬å£°ç§°æ˜¯"ç®€å•æ›´æ–°"æˆ–"è½»å¾®ä¿®æ”¹"ï¼Œä½†æ‰§è¡Œå›¾çš„æ·±åº¦è¾¾åˆ° 4 æˆ–æ›´é«˜ï¼Œè¯·åˆ†ææ˜¯å¦å­˜åœ¨"æ¶æ„éšè—æ·±åº¦"çš„é£é™©ã€‚è¯„ä¼°å®é™…æ‰§è¡Œå¤æ‚åº¦æ˜¯å¦ä¸æ–‡æœ¬æè¿°ä¸€è‡´ã€‚

### 3. [Function Semantic Match] å‡½æ•°è¯­ä¹‰åŒ¹é…
æ£€æŸ¥å›¾ä¸­æ‰§è¡Œçš„å‡½æ•°åï¼ˆå¦‚ execute, upgradeTo, transfer ç­‰ï¼‰æ˜¯å¦ä¸ææ¡ˆæ–‡æœ¬æ‰€è¿°çš„æ„å›¾å»åˆã€‚è¯†åˆ«ä»»ä½•è¯­ä¹‰ä¸ä¸€è‡´æˆ–æœªå…¬å¼€çš„å‡½æ•°è°ƒç”¨ã€‚

## è¾“å…¥æ•°æ®

### ææ¡ˆæ–‡æœ¬æè¿°ï¼š
```
{proposal_description}
```

### æ‰§è¡Œå›¾æè¿°ï¼š
```
{graph_description}
```

## è¾“å‡ºè¦æ±‚

è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºå®¡è®¡ç»“æœï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

```json
{{
  "consistency_score": <1-10 çš„æ•´æ•°ï¼Œ10 è¡¨ç¤ºå®Œå…¨ä¸€è‡´ï¼Œ1 è¡¨ç¤ºä¸¥é‡ä¸ä¸€è‡´>,
  "conflict_detection": {{
    "unaccounted_contracts": [
      {{
        "address": "<åˆçº¦åœ°å€>",
        "risk_level": "<low|medium|high>",
        "description": "<ä¸ºä»€ä¹ˆè¿™ä¸ªåœ°å€æœªåœ¨æ–‡æœ¬ä¸­æåˆ°ï¼Œå¯èƒ½çš„é£é™©>",
        "is_system_contract": <true|false>,
        "contract_type": "<SYSTEM_LEVEL_CALL|UNACCOUNTED_CONTRACT>"
      }}
    ],
    "system_level_calls": [
      {{
        "address": "<ç³»ç»Ÿåˆçº¦åœ°å€>",
        "type": "<é¢„ç¼–è¯‘åˆçº¦|L2ç³»ç»Ÿåˆçº¦|ä»£ç†è½¬å‘>",
        "description": "<ç³»ç»Ÿåˆçº¦çš„ç”¨é€”è¯´æ˜>"
      }}
    ],
    "mentioned_contracts": [
      "<åœ¨æ–‡æœ¬ä¸­æ˜ç¡®æåˆ°çš„åˆçº¦åœ°å€åˆ—è¡¨>"
    ]
  }},
  "depth_analysis": {{
    "claimed_complexity": "<æ–‡æœ¬ä¸­å£°ç§°çš„å¤æ‚åº¦æè¿°>",
    "actual_depth": <å®é™…å›¾æ·±åº¦>,
    "depth_mismatch": <true|false>,
    "risk_assessment": "<å¦‚æœå­˜åœ¨æ·±åº¦ä¸åŒ¹é…ï¼Œè¯„ä¼°é£é™©ç­‰çº§å’ŒåŸå› >"
  }},
  "function_semantic_match": {{
    "matched_functions": [
      {{
        "function": "<å‡½æ•°å>",
        "description": "<ä¸æ–‡æœ¬æè¿°çš„åŒ¹é…æƒ…å†µ>"
      }}
    ],
    "unmatched_functions": [
      {{
        "function": "<å‡½æ•°å>",
        "description": "<ä¸ºä»€ä¹ˆè¿™ä¸ªå‡½æ•°è°ƒç”¨ä¸æ–‡æœ¬æè¿°ä¸åŒ¹é…>",
        "risk_level": "<low|medium|high>"
      }}
    ]
  }},
  "potential_risks": [
    {{
      "type": "<é£é™©ç±»å‹ï¼Œå¦‚ UNACCOUNTED_CONTRACT, DEPTH_MISMATCH, FUNCTION_MISMATCH ç­‰>",
      "severity": "<low|medium|high|critical>",
      "description": "<è¯¦ç»†çš„é£é™©æè¿°>",
      "recommendation": "<å»ºè®®çš„åº”å¯¹æªæ–½>"
    }}
  ],
  "security_conclusion": "<æ€»ä½“å®‰å…¨ç»“è®ºï¼ŒåŒ…æ‹¬æ˜¯å¦å»ºè®®é€šè¿‡æ­¤ææ¡ˆ>",
  "summary": "<ç®€è¦æ€»ç»“ï¼Œ2-3 å¥è¯>"
}}
```

è¯·ä»”ç»†åˆ†æï¼Œç¡®ä¿è¾“å‡ºæœ‰æ•ˆçš„ JSON æ ¼å¼ã€‚"""
        
        return prompt
    
    def parse_llm_response(self, response_text: str) -> Dict[str, Any]:
        """
        è§£æ LLM å“åº”ï¼Œæå– JSON
        
        Args:
            response_text: LLM å“åº”æ–‡æœ¬
            
        Returns:
            è§£æåçš„ JSON å­—å…¸
        """
        # å°è¯•æå– JSONï¼ˆå¯èƒ½è¢« ```json ... ``` åŒ…è£¹ï¼‰
        json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            # å°è¯•æå– {...} æ ¼å¼çš„ JSON
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
            else:
                json_str = response_text
        
        try:
            result = json.loads(json_str)
            return result
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse LLM response as JSON: {e}")
            logger.debug(f"Response text: {response_text[:500]}")
            # è¿”å›ä¸€ä¸ªé»˜è®¤ç»“æ„
            return {
                "consistency_score": 5,
                "error": "Failed to parse LLM response",
                "raw_response": response_text[:1000]
            }
    
    def generate_markdown_report(self, audit_result: Dict[str, Any], 
                                 proposal_id: Optional[str] = None) -> str:
        """
        ç”Ÿæˆ Markdown æ ¼å¼çš„å®¡è®¡æŠ¥å‘Š
        
        Args:
            audit_result: å®¡è®¡ç»“æœå­—å…¸
            proposal_id: ææ¡ˆ IDï¼ˆå¯é€‰ï¼‰
            
        Returns:
            Markdown æ ¼å¼çš„æŠ¥å‘Šæ–‡æœ¬
        """
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        report = f"""# DAO ææ¡ˆå®¡è®¡æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {timestamp}  
**ææ¡ˆ ID**: {proposal_id or "N/A"}

---

## ğŸ“Š ä¸€è‡´æ€§è¯„åˆ†

**è¯„åˆ†**: **{audit_result.get('consistency_score', 'N/A')}/10**

{self._get_score_description(audit_result.get('consistency_score', 5))}

---

## ğŸ” å†²çªæ£€æµ‹ (Conflict Detection)

### æœªå…¬å¼€çš„åˆçº¦åœ°å€

"""
        
        # ç³»ç»Ÿçº§è°ƒç”¨
        system_calls = audit_result.get("conflict_detection", {}).get("system_level_calls", [])
        if system_calls:
            report += "### ç³»ç»Ÿçº§å¸¸è§„è°ƒç”¨\n\n"
            report += "ä»¥ä¸‹åœ°å€å±äºç³»ç»Ÿçº§åˆçº¦ï¼Œå±äºæ­£å¸¸è°ƒç”¨ï¼Œæ— éœ€åœ¨ææ¡ˆæ–‡æœ¬ä¸­ç‰¹åˆ«è¯´æ˜ï¼š\n\n"
            for call in system_calls:
                report += f"- âœ… **{call.get('address', 'N/A')}**\n"
                report += f"  - ç±»å‹: `{call.get('type', 'N/A')}`\n"
                report += f"  - è¯´æ˜: {call.get('description', 'N/A')}\n\n"
        
        # æœªæŠ«éœ²çš„ç¬¬ä¸‰æ–¹åœ°å€ï¼ˆéç³»ç»Ÿçº§ï¼‰
        unaccounted = audit_result.get("conflict_detection", {}).get("unaccounted_contracts", [])
        # è¿‡æ»¤æ‰ç³»ç»Ÿåˆçº¦
        non_system_unaccounted = [
            c for c in unaccounted 
            if not c.get("is_system_contract", False) and 
               c.get("contract_type") != "SYSTEM_LEVEL_CALL"
        ]
        
        if non_system_unaccounted:
            report += "### âš ï¸ æœªå…¬å¼€çš„ç¬¬ä¸‰æ–¹åˆçº¦åœ°å€\n\n"
            report += "ä»¥ä¸‹åœ°å€æœªåœ¨ææ¡ˆæ–‡æœ¬ä¸­æ˜ç¡®æåˆ°ï¼Œä¸”ä¸å±äºç³»ç»Ÿçº§åˆçº¦ï¼Œéœ€è¦è¿›ä¸€æ­¥å®¡æŸ¥ï¼š\n\n"
            for contract in non_system_unaccounted:
                risk_emoji = self._get_risk_emoji(contract.get("risk_level", "medium"))
                report += f"- {risk_emoji} **{contract.get('address', 'N/A')}**\n"
                report += f"  - é£é™©ç­‰çº§: `{contract.get('risk_level', 'medium').upper()}`\n"
                report += f"  - è¯´æ˜: {contract.get('description', 'N/A')}\n\n"
        elif not system_calls:
            report += "âœ… æœªå‘ç°æœªå…¬å¼€çš„åˆçº¦åœ°å€ã€‚\n\n"
        
        mentioned = audit_result.get("conflict_detection", {}).get("mentioned_contracts", [])
        if mentioned:
            report += "### æ–‡æœ¬ä¸­æ˜ç¡®æåˆ°çš„åˆçº¦\n\n"
            for addr in mentioned:
                report += f"- `{addr}`\n"
            report += "\n"
        
        report += "---\n\n## ğŸ“ æ·±åº¦åˆ†æ (Depth Analysis)\n\n"
        
        depth_analysis = audit_result.get("depth_analysis", {})
        claimed = depth_analysis.get("claimed_complexity", "N/A")
        actual_depth = depth_analysis.get("actual_depth", "N/A")
        mismatch = depth_analysis.get("depth_mismatch", False)
        
        report += f"- **æ–‡æœ¬å£°ç§°çš„å¤æ‚åº¦**: {claimed}\n"
        report += f"- **å®é™…æ‰§è¡Œæ·±åº¦**: {actual_depth}\n"
        report += f"- **æ·±åº¦ä¸åŒ¹é…**: {'âš ï¸ æ˜¯' if mismatch else 'âœ… å¦'}\n\n"
        
        if mismatch:
            risk_assessment = depth_analysis.get("risk_assessment", "N/A")
            report += f"**é£é™©è¯„ä¼°**: {risk_assessment}\n\n"
        
        report += "---\n\n## ğŸ”— å‡½æ•°è¯­ä¹‰åŒ¹é… (Function Semantic Match)\n\n"
        
        func_match = audit_result.get("function_semantic_match", {})
        
        matched = func_match.get("matched_functions", [])
        if matched:
            report += "### âœ… åŒ¹é…çš„å‡½æ•°\n\n"
            for func in matched:
                report += f"- **{func.get('function', 'N/A')}**: {func.get('description', 'N/A')}\n"
            report += "\n"
        
        unmatched = func_match.get("unmatched_functions", [])
        if unmatched:
            report += "### âš ï¸ ä¸åŒ¹é…çš„å‡½æ•°\n\n"
            for func in unmatched:
                risk_emoji = self._get_risk_emoji(func.get("risk_level", "medium"))
                report += f"- {risk_emoji} **{func.get('function', 'N/A')}**\n"
                report += f"  - é£é™©ç­‰çº§: `{func.get('risk_level', 'medium').upper()}`\n"
                report += f"  - è¯´æ˜: {func.get('description', 'N/A')}\n\n"
        else:
            report += "âœ… æ‰€æœ‰å‡½æ•°è°ƒç”¨ä¸æ–‡æœ¬æè¿°åŒ¹é…ã€‚\n\n"
        
        report += "---\n\n## âš ï¸ æ½œåœ¨é£é™©ç‚¹\n\n"
        
        risks = audit_result.get("potential_risks", [])
        if risks:
            for i, risk in enumerate(risks, 1):
                severity_emoji = self._get_severity_emoji(risk.get("severity", "medium"))
                report += f"### {i}. {severity_emoji} {risk.get('type', 'UNKNOWN_RISK')}\n\n"
                report += f"- **ä¸¥é‡ç¨‹åº¦**: `{risk.get('severity', 'medium').upper()}`\n"
                report += f"- **æè¿°**: {risk.get('description', 'N/A')}\n"
                report += f"- **å»ºè®®**: {risk.get('recommendation', 'N/A')}\n\n"
        else:
            report += "âœ… æœªå‘ç°æ˜æ˜¾çš„æ½œåœ¨é£é™©ã€‚\n\n"
        
        report += "---\n\n## ğŸ”’ å®‰å…¨ç»“è®º\n\n"
        report += f"{audit_result.get('security_conclusion', 'N/A')}\n\n"
        
        report += "---\n\n## ğŸ“ æ€»ç»“\n\n"
        report += f"{audit_result.get('summary', 'N/A')}\n\n"
        
        report += "---\n\n*æœ¬æŠ¥å‘Šç”± AI è‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒã€‚å»ºè®®ç»“åˆäººå·¥å®¡è®¡è¿›è¡Œæœ€ç»ˆå†³ç­–ã€‚*\n"
        
        return report
    
    def _get_score_description(self, score: int) -> str:
        """è·å–è¯„åˆ†æè¿°"""
        if score >= 9:
            return "âœ… **ä¼˜ç§€**: ææ¡ˆæ–‡æœ¬ä¸æ‰§è¡Œè½¨è¿¹é«˜åº¦ä¸€è‡´ï¼Œæ— æ˜æ˜¾é£é™©ã€‚"
        elif score >= 7:
            return "âœ… **è‰¯å¥½**: ææ¡ˆæ–‡æœ¬ä¸æ‰§è¡Œè½¨è¿¹åŸºæœ¬ä¸€è‡´ï¼Œå­˜åœ¨å°‘é‡å¯æ¥å—çš„å·®å¼‚ã€‚"
        elif score >= 5:
            return "âš ï¸ **ä¸­ç­‰**: ææ¡ˆæ–‡æœ¬ä¸æ‰§è¡Œè½¨è¿¹å­˜åœ¨ä¸€å®šå·®å¼‚ï¼Œéœ€è¦è¿›ä¸€æ­¥å®¡æŸ¥ã€‚"
        elif score >= 3:
            return "âš ï¸ **è¾ƒå·®**: ææ¡ˆæ–‡æœ¬ä¸æ‰§è¡Œè½¨è¿¹å­˜åœ¨æ˜æ˜¾å·®å¼‚ï¼Œå­˜åœ¨æ½œåœ¨é£é™©ã€‚"
        else:
            return "âŒ **ä¸¥é‡**: ææ¡ˆæ–‡æœ¬ä¸æ‰§è¡Œè½¨è¿¹ä¸¥é‡ä¸ä¸€è‡´ï¼Œå­˜åœ¨é«˜é£é™©ã€‚"
    
    def _get_risk_emoji(self, risk_level: str) -> str:
        """è·å–é£é™©ç­‰çº§ emoji"""
        level_map = {
            "low": "ğŸŸ¢",
            "medium": "ğŸŸ¡",
            "high": "ğŸŸ ",
            "critical": "ğŸ”´"
        }
        return level_map.get(risk_level.lower(), "âšª")
    
    def _get_severity_emoji(self, severity: str) -> str:
        """è·å–ä¸¥é‡ç¨‹åº¦ emoji"""
        return self._get_risk_emoji(severity)
    
    def audit(self,
              proposal_path: str = "data/proposals/collected_proposal.json",
              graph_desc_path: str = "outputs/graph_description.txt",
              output_path: str = "outputs/reports/audit_report.md") -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„å®¡è®¡æµç¨‹
        
        Args:
            proposal_path: ææ¡ˆæ–‡ä»¶è·¯å¾„
            graph_desc_path: å›¾æè¿°æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºæŠ¥å‘Šè·¯å¾„
            
        Returns:
            å®¡è®¡ç»“æœå­—å…¸
        """
        logger.info("Starting audit process")
        
        # 1. åŠ è½½æ•°æ®
        proposal_data = self.load_proposal(proposal_path)
        proposal_description = proposal_data.get("description", "")
        proposal_id = str(proposal_data.get("id", "N/A"))
        
        graph_description = self.load_graph_description(graph_desc_path)
        
        # 2. æ„å»º Prompt
        prompt = self.build_audit_prompt(proposal_description, graph_description)
        
        # 3. è°ƒç”¨ LLM
        logger.info("Calling LLM for audit analysis")
        system_prompt = "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ™ºèƒ½åˆçº¦å®‰å…¨å®¡è®¡ä¸“å®¶ï¼Œæ“…é•¿åˆ†æ DAO ææ¡ˆçš„ä¸€è‡´æ€§å’Œå®‰å…¨æ€§ã€‚"
        
        try:
            response = self.llm.call(prompt, system_prompt=system_prompt)
            logger.info("LLM response received")
        except Exception as e:
            logger.error(f"Error calling LLM: {e}")
            raise
        
        # 4. è§£æå“åº”
        audit_result = self.parse_llm_response(response)
        audit_result["proposal_id"] = proposal_id
        
        # 5. ç”ŸæˆæŠ¥å‘Š
        markdown_report = self.generate_markdown_report(audit_result, proposal_id)
        
        # 6. ä¿å­˜æŠ¥å‘Š
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"Saving audit report to {output_file}")
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(markdown_report)
        
        logger.info("Audit process completed")
        
        return audit_result


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="DAO ææ¡ˆå®¡è®¡å·¥å…·")
    parser.add_argument(
        "--proposal",
        type=str,
        default="data/proposals/collected_proposal.json",
        help="ææ¡ˆ JSON æ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--graph-desc",
        type=str,
        default="outputs/graph_description.txt",
        help="å›¾æè¿°æ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--output",
        type=str,
        default="outputs/reports/audit_report.md",
        help="è¾“å‡ºæŠ¥å‘Šè·¯å¾„"
    )
    parser.add_argument(
        "--llm-type",
        type=str,
        choices=["anthropic", "openai"],
        default="anthropic",
        help="LLM ç±»å‹"
    )
    parser.add_argument(
        "--api-key",
        type=str,
        default=None,
        help="API Keyï¼ˆå¦‚æœä¸æä¾›ï¼Œä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰"
    )
    parser.add_argument(
        "--model",
        type=str,
        default=None,
        help="æ¨¡å‹åç§°ï¼ˆå¦‚æœä¸æä¾›ï¼Œä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰"
    )
    parser.add_argument(
        "--base-url",
        type=str,
        default=None,
        help="è‡ªå®šä¹‰ API åŸºç¡€ URLï¼ˆç”¨äºç¬¬ä¸‰æ–¹å¹³å°ï¼‰"
    )
    
    args = parser.parse_args()
    
    # åˆ›å»ºå®¡è®¡å™¨
    auditor = Auditor(
        llm_type=args.llm_type,
        api_key=args.api_key,
        model=args.model,
        base_url=args.base_url
    )
    
    # æ‰§è¡Œå®¡è®¡
    result = auditor.audit(
        proposal_path=args.proposal,
        graph_desc_path=args.graph_desc,
        output_path=args.output
    )
    
    print(f"\nAudit completed!")
    print(f"Consistency score: {result.get('consistency_score', 'N/A')}/10")
    print(f"Report saved to: {args.output}")


if __name__ == "__main__":
    main()
